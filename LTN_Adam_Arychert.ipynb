{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ltn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_time', 'GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
       "       'DEMAND_LIMIT_INDICATOR', 'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
       "       'BATTERY_CHARGED_ENERGY', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
       "       'PV_ENERGY', 'WALLBOX_ALPHA_ENERGY', 'WALLBOX_ALPHA_POWER',\n",
       "       'WALLBOX_1_ENERGY', 'WALLBOX_1_POWER', 'WALLBOX_2_ENERGY',\n",
       "       'WALLBOX_2_POWER', 'WALLBOX_3_ENERGY', 'WALLBOX_3_POWER',\n",
       "       'WALLBOX_A_ENERGY', 'WALLBOX_A_POWER', 'WALLBOX_B_ENERGY',\n",
       "       'WALLBOX_B_POWER', 'WALLBOX_C_ENERGY', 'WALLBOX_C_POWER',\n",
       "       'WALLBOX_FASTCHARGER_ENERGY', 'WALLBOX_FASTCHARGER_POWER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = s_data[['_time','GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
    "      #  'DEMAND_LIMIT_INDICATOR', \n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'BATTERY_CHARGED_ENERGY','WALLBOX_FASTCHARGER_POWER', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
    "       'PV_ENERGY'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    # elif row[\"BATTERY_SOC\"] < 15:\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the labeling function to create the new column \"DRAWN_FROM\"\n",
    "s_data[\"DRAWN_FROM\"] = s_data.apply(label_charging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.5 # Tolerance for the power limit\n",
    "SOC_less_15 = s_data[(s_data[\"BATTERY_SOC\"]<=15) & (s_data[\"BATTERY_DISCHARGE_POWER\"]<=0)]\n",
    "SOC_less_40_1 = s_data[(s_data[\"BATTERY_SOC\"]>15) &(s_data[\"BATTERY_SOC\"]<40) & (s_data[\"GARAGE_EXTERNAL_POWER\"]<50) & (s_data[\"BATTERY_DISCHARGE_POWER\"]<0)]\n",
    "SOC_less_40_2 = s_data[(s_data[\"BATTERY_SOC\"]>15) &(s_data[\"BATTERY_SOC\"]<40) & (s_data[\"GARAGE_EXTERNAL_POWER\"]<=(50+delta)) & ((50-delta)<=s_data[\"GARAGE_EXTERNAL_POWER\"]) & (s_data[\"BATTERY_DISCHARGE_POWER\"]>=0)]\n",
    "SOC_more_40 = s_data[(s_data[\"BATTERY_SOC\"]>=40) & (s_data[\"BATTERY_DISCHARGE_POWER\"]>=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset, that is kept: 16.313381110998957%\n"
     ]
    }
   ],
   "source": [
    "df_GT = pd.concat([SOC_less_15, SOC_less_40_1, SOC_less_40_2, SOC_more_40], ignore_index=True)\n",
    "df_GT = df_GT.drop_duplicates()\n",
    "print(f\"Percentage of dataset, that is kept: {len(df_GT)/len(s_data)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = df_GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows that do not follow the rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_time', 'GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT', 'BATTERY_SOC',\n",
       "       'BATTERY_DISCHARGE_POWER', 'BATTERY_CHARGED_ENERGY',\n",
       "       'WALLBOX_FASTCHARGER_POWER', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
       "       'PV_ENERGY', 'DRAWN_FROM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows that have the label \"Battery Charged from Grid\"\n",
    "s_data_small = s_data[s_data[\"DRAWN_FROM\"] == \"Battery Discharge Stopped due to Battery Health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    157.000000\n",
       "mean       9.914013\n",
       "std        1.761572\n",
       "min        7.500000\n",
       "25%        8.500000\n",
       "50%        9.500000\n",
       "75%       11.500000\n",
       "max       12.500000\n",
       "Name: BATTERY_SOC, dtype: float64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data_small[\"BATTERY_SOC\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRAWN_FROM\n",
       "Battery Charged from Grid                          54818\n",
       "Partially Covered by Local Battery                  4467\n",
       "Battery Discharge Stopped due to Battery Health      157\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data['DRAWN_FROM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = s_data.drop(['_time','DEMAND_LIMIT', 'DRAWN_FROM', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY', 'PV_POWER','PV_ENERGY', 'DRAWN_FROM'], axis=1)\n",
    "target = s_data['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRAWN_FROM\n",
       "Battery Charged from Grid                          54818\n",
       "Partially Covered by Local Battery                  4467\n",
       "Battery Discharge Stopped due to Battery Health      157\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Tensor Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: \"Battery Charged from Grid\" is encoded as 0\n",
      "Original Class: \"Battery Discharge Stopped due to Battery Health\" is encoded as 1\n",
      "Original Class: \"Partially Covered by Local Battery\" is encoded as 2\n"
     ]
    }
   ],
   "source": [
    "# Print classes and their labels\n",
    "for label, original_class in enumerate(encoder.classes_):\n",
    "    print(f'Original Class: \"{original_class}\" is encoded as {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of the target\n",
    "unique_values = np.unique(en_targ)\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(4, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "\n",
    "# we define the connectives, quantifiers, and the SatAgg\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = self.batch_size // len(self.unique_labels)\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.3164, 43.5000, -0.4290,  0.1500],\n",
       "        [49.9570, 35.0000, 36.2030, 77.7036],\n",
       "        [47.8516, 29.0000,  2.2110, 49.8447],\n",
       "        ...,\n",
       "        [ 0.2871, 40.5000, -0.7610,  0.1704],\n",
       "        [15.3125, 41.0000, -0.4990,  0.1536],\n",
       "        [14.6426, 40.5000, -0.4210,  0.1618]])"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(features_train, target_train, 64, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([43840,   127,  3586], dtype=int64))"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values of the target and how much there is of each\n",
    "unique_values, counts = np.unique(target_train, return_counts=True)\n",
    "unique_values, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4036 | Train Sat 0.634 | Test Sat 0.634 | Train Acc 0.822 | Test Acc 0.823\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m x_C \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_C\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# class C examples\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(x_B)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sat_agg \u001b[38;5;241m=\u001b[39m SatAgg(\n\u001b[1;32m---> 13\u001b[0m     Forall(x_A, \u001b[43mP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[0;32m     14\u001b[0m     Forall(x_B, P(x_B, l_B, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[0;32m     15\u001b[0m     Forall(x_C, P(x_C, l_C, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m sat_agg\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:613\u001b[0m, in \u001b[0;36mPredicate.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m proc_objs, output_vars, output_shape \u001b[38;5;241m=\u001b[39m process_ltn_objects(inputs)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# the management of the input is left to the model or the lambda function\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproc_objs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# check if output of predicate contains only truth values, namely values in the range [0., 1.]\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mlogical_and(output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, output \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m), \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[114], line 33\u001b[0m, in \u001b[0;36mLogitsToPredicate.forward\u001b[1;34m(self, x, l, training)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, l, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[0;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(probs \u001b[38;5;241m*\u001b[39m l, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[114], line 11\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 11\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m     13\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(60):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "        # print(x_B)\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " epoch 0 | loss 0.3923 | Train Sat 0.656 | Test Sat 0.661 | Train Acc 0.844 | Test Acc 0.852\n",
    " epoch 20 | loss 0.2906 | Train Sat 0.710 | Test Sat 0.717 | Train Acc 0.909 | Test Acc 0.913\n",
    " epoch 40 | loss 0.2889 | Train Sat 0.711 | Test Sat 0.718 | Train Acc 0.910 | Test Acc 0.917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def labEq2(tensor):\n",
    "    return tensor == 2  \n",
    "\n",
    "labEq2 = ltn.Predicate(None, labEq2)\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor <= 13  # returns True if Battery_SOC > 10\n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "\n",
    "def phi(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    sc = features[1].view(-1,1)\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall(s, Implies(Battery_SOC_small(s), labEq2(y)), p=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        labels = torch.tensor(labels)\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sat_level_phi(train_loader, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor(0.8575)\n",
    "tensor(0.7295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_tensor = torch.tensor(s_data['BATTERY_SOC'].values, dtype=torch.float32)\n",
    "external_power_tensor = torch.tensor(s_data['GARAGE_EXTERNAL_POWER'].values, dtype=torch.float32)\n",
    "demand_limit_tensor = torch.tensor(s_data['DEMAND_LIMIT'].values, dtype=torch.float32)\n",
    "discard_power_tensor = torch.tensor(s_data[\"BATTERY_DISCHARGE_POWER\"].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how the conditions function utilizes the model\n",
    "def conditions(soc, external_power, demand_limit):\n",
    "    inputs = torch.stack([soc, external_power, demand_limit], dim=1)\n",
    "    return mlp(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule3():\n",
    "    condition = (soc_tensor <= 13) & (external_power_tensor < demand_limit_tensor) & (discard_power_tensor <= 0)\n",
    "    return torch.mean(condition.float() * conditions(soc_tensor, external_power_tensor, demand_limit_tensor)[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we tried to again predict the peak shaving, and check for different predicates what is their satisfaction level.\n",
    "- it would make sense that if we have a predicate: SOC <= 20 stop peak shaving, than if the treshold is good (or the rule in general), than the satisfaction of this rule will be high.\n",
    "- This could also allow us to check the relation to the solar panels ? -> if the predicat that includes it does better than that that does not include it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 10% of the dataset \n",
    "data_small = s_data.sample(frac=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_peak_shaving(row):\n",
    "    if row['GARAGE_EXTERNAL_POWER'] >= row['DEMAND_LIMIT']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_small['Peak_Shaving'] = data_small.apply(check_peak_shaving, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds\n",
    "battery_discharge_power_threshold = 0\n",
    "pv_power_threshold = 0.5\n",
    "\n",
    "def adjust_peak_shaving(row):\n",
    "    if row['Peak_Shaving'] == True:\n",
    "        if row['BATTERY_DISCHARGE_POWER'] > battery_discharge_power_threshold or row['PV_POWER'] > pv_power_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small['Peak_Shaving'] = data_small.apply(adjust_peak_shaving, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_small.drop(['_time','Peak_Shaving','DEMAND_LIMIT', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY'], axis=1)\n",
    "target = data_small['Peak_Shaving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'DRAWN_FROM' column and transform it\n",
    "features['DRAWN_FROM'] = le.fit_transform(features['DRAWN_FROM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "target_train = torch.tensor(target_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n",
    "target_test = torch.tensor(target_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try first with a simple rule \n",
    "if GARAGE_EXTERNAL_POWER > DEMAND_LIMIT and SOC >= 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "# we define predicate A\n",
    "class ModelA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelA, self).__init__()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.layer1 = torch.nn.Linear(6, 16)  \n",
    "        self.layer2 = torch.nn.Linear(16, 16)\n",
    "        self.layer3 = torch.nn.Linear(16, 1)\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.layer1(x))\n",
    "        x = self.elu(self.layer2(x))\n",
    "        return self.sigmoid(self.layer3(x))\n",
    "\n",
    "\n",
    "A = ltn.Predicate(ModelA())\n",
    "\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# this is a standard PyTorch DataLoader to load the dataset for the training and testing of the model\n",
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "\n",
    "# define metrics for evaluation of the model\n",
    "\n",
    "# it computes the overall satisfaction level on the knowledge base using the given data loader (train or test)\n",
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[torch.nonzero(labels)])  # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\",\n",
    "                               data[torch.nonzero(torch.logical_not(labels))])  # negative examples\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = A.model(data).detach().numpy()\n",
    "        predictions = np.where(predictions > 0.5, 1., 0.).flatten()\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n",
    "\n",
    "# create train and test loader, 50 points each\n",
    "# batch size is 64, meaning there is only one batch for epoch\n",
    "train_loader = DataLoader(features_train, target_train, 1024, True)\n",
    "test_loader = DataLoader(features_test, target_test, 1024, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 1 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axioms that are tried\n",
    "\n",
    "- for every instance if peak shaving is true than Battery_SOC > 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARAGE_EXTERNAL_POWER > 50\n",
    "\n",
    "def P(tensor):\n",
    "    return tensor >= 50\n",
    "\n",
    "# Wrap the predicate in an LTN Predicate\n",
    "P = ltn.Predicate(None, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak shaving is True\n",
    "def Q(tensor):\n",
    "    return tensor >= 0.5  # returns True if p_shav is True\n",
    "\n",
    "# Wrap the predicate in an LTN Predicate\n",
    "Q = ltn.Predicate(None, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phi(features, labels):\n",
    "\n",
    "    features = features[0].view(-1, 1)\n",
    "    labels = labels.view(-1, 1)\n",
    "    # Create a variable that represents the data\n",
    "    p = ltn.Variable(\"p\", features)\n",
    "    q = ltn.Variable(\"q\", labels)\n",
    "\n",
    "\n",
    "    # Return the satisfaction degree of the formula\n",
    "\n",
    "    return Forall(p, Implies(P(p), Q(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "\n",
    "def PeakShaving(tensor):\n",
    "    return tensor >= 0.5  # returns True if peak shaving is True\n",
    "\n",
    "PeakShaving = ltn.Predicate(None, PeakShaving)\n",
    "\n",
    "def Battery_SOC_Greater_15(tensor):\n",
    "    return tensor > 35  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_Greater_15 = ltn.Predicate(None, Battery_SOC_Greater_15)\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 45  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "\n",
    "def phi(features, label):\n",
    "   \n",
    "    label = label.view(-1, 1)\n",
    "    sc = features[1].view(-1,1)\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall([y, s], Implies(PeakShaving(y), And(Battery_SOC_Greater_15(s), Battery_SOC_small(s))), p=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could be interesting is more general rules, that don't require the tresholds\n",
    "- for all x if peak shaving than energy is given from both sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "\n",
    "def phiComp(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #power plant power\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([y, b, p], Implies(PeakShaving(y), And(gives_energy(b), gives_energy(p))), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sat_level_phi(test_loader, phiComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "def gets_charged(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor < 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "gets_charged = ltn.Predicate(None, gets_charged)\n",
    "\n",
    "def phit2(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #batery power\n",
    "  \n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([b, p], Implies(gives_energy(p), gives_energy(b)), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_sat_level_phi(train_loader, phit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        # p_shav = labels\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A))),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f | Phi Sat %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader), compute_sat_level_phi(test_loader, phit2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for now: \n",
    "- check whith a more complicated new rule how does the satisfaction work \n",
    "\n",
    "Idea:\n",
    "- to learn the treshold we need to save them as variables and create another Predicate to optimze them. But what do we base the optimization on? \n",
    "\n",
    "What can we use for loss? Assuming we want to learn tresholds, what would we use to validate how good we do on the data? \n",
    "- Maybe based on my simple labeled peak shaving? -- For which values is the peak shaving true. Should this be done with another NN model? I guess we save the tresholds as predicates, similarly as I did with Battery_SOC_Greater_15, but the treshold has to be learnable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that guesses peak shaving based on the ground truth\n",
    "\n",
    "For what SOC\n",
    "- e-cars charging is completely covered by the local battery\n",
    "- e-cars charging power is covered by local battery.\n",
    "- local battery is charged from the grid.\n",
    "- Battery discharging is stopped due to battery health\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"POWER_DEMAND\"] = ds[\"WALLBOX_1_POWER\"] + ds[\"WALLBOX_2_POWER\"] + ds[\"WALLBOX_3_POWER\"] + ds[\"WALLBOX_A_POWER\"] + ds[\"WALLBOX_B_POWER\"] + ds[\"WALLBOX_C_POWER\"] + ds[\"WALLBOX_FASTCHARGER_POWER\"]\n",
    "ds[\"POWER_SUPPLY\"] = ds[\"GARAGE_EXTERNAL_POWER\"] + ds[\"PV_POWER\"] + ds[\"BATTERY_DISCHARGE_POWER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-cars charging is completely covered by the local battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_covered_prc = ((ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"]) >= 0.98).any()\n",
    "\n",
    "print(f\"Does 'BATTERY_DISCHARGE_POWER' ever cover 100% of 'POWER_SUPPLY'? {is_covered_prc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.95:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] > 0.05:\n",
    "        return \"covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] < 0:\n",
    "        return \"charged\"\n",
    "    else:\n",
    "        return \"stopped\"\n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.9:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] > 0 or row[\"BATTERY_DISCHARGE_POWER\"] > 0:\n",
    "        return \"covered\"\n",
    "    else:\n",
    "        return \"charged\"\n",
    "    \n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.groupby('Label')['BATTERY_SOC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['BATTERY_DISCHARGE_POWER'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that, we can try to optimize tresholds for SOC so that they help us predict the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_tensor = torch.tensor(ds['BATTERY_SOC'].values, dtype=torch.float32)\n",
    "external_power_tensor = torch.tensor(ds['GARAGE_EXTERNAL_POWER'].values, dtype=torch.float32)\n",
    "demand_limit_tensor = torch.tensor(ds['DEMAND_LIMIT'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should it work? \n",
    "- the model should predict the \"Label\" (from battery SOC?), and than based on how good the prediction with a curent treshold is update the tresholds\n",
    "- there are 3 tresholds: one for when the battery is covering for all of the grid, one for when the batery is covering some part of the needed energy, pme for whem it is just charging\n",
    "\n",
    "How do I make the treshold be something that gets learned?\n",
    "- predicate 1: learning labels from ds based on battery SOC and tresholds \n",
    "- predicate 2: learning tresholds based on the labels and battery SOC \n",
    "\n",
    "Axioms: \n",
    "- for all x (SOC values): Label IMPLIES x in treshold => if the label is correct than the value is in the treshold   \n",
    "\n",
    "WHAT ACTUALLY SHOULD BE DONE IS TO MAKE A TRESHOLDS PREDICTION NN AND ADD SOME LOGIC RULES THAT SHOULD BE SATISFIED FOR IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1: take the SOC and tresholds and compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(3, 16, 16, 1)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.sigmoid(self.linear_layers[-1](x))\n",
    "        return out\n",
    "    \n",
    "\n",
    "Label = ltn.Predicate(MLP([1, 20, 3]))  # 3 output classes: \"charged\", \"covered\", \"completely covered\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define connectives, quantifiers, and SatAgg\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2: take label and SOC and compute treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_ds = ds[ds[\"Label\"] == \"charged\"]\n",
    "covered_ds = ds[ds[\"Label\"] == \"covered\"]\n",
    "completely_covered_ds = ds[ds[\"Label\"] == \"completely covered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(3, 16, 16, 1)):\n",
    "        super(TMLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.linear_layers[-1](x)\n",
    "        return out\n",
    "    \n",
    "t1 = ltn.Predicate(TMLP([2, 20, 1])) # output is a treshold, input is a battery soc and label \n",
    "\n",
    "# f = ltn.Function(TMLP())\n",
    "# alpha = 0.05\n",
    "tr1 = ltn.Constant(torch.tensor([80]), trainable=True)\n",
    "tr2 = ltn.Constant(torch.tensor([40]), trainable=True)\n",
    "tr3 = ltn.Constant(torch.tensor([15]), trainable=True)\n",
    "\n",
    "# alpha = 0.05\n",
    "# Eq = ltn.Predicate(func=lambda u,v: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(u-v), dim=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "\n",
    "# def compute_sat_level(loader):\n",
    "#     mean_sat = 0\n",
    "#     for x_d, y_d in loader:\n",
    "#         x = ltn.Variable(\"x\", x_d)\n",
    "#         y = ltn.Variable(\"y\", y_d)\n",
    "#         mean_sat += Forall(ltn.diag(x,y), Eq(f(x), y)).value\n",
    "#     mean_sat /= len(loader)\n",
    "#     return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = f.model(data).detach().numpy()\n",
    "        # predictions = np.where(predictions > 0.5, 1., 0.).flatten()\n",
    "        mean_accuracy += torch.nn.MSELoss(labels, predictions)\n",
    "    return mean_accuracy / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(ds[\"Label\"].values)\n",
    "label_tensor = torch.tensor(encoded_labels).float()\n",
    "# label_tensor = torch.tensor(encoded_labels, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prepare the data\n",
    "soc_tensor = torch.tensor(ds['BATTERY_SOC'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataloader = DataLoader(soc_tensor, label_tensor, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def phi1(features, label):\n",
    "#     print(features)\n",
    "#     print(label)\n",
    "#     label = label.view(-1, 1)\n",
    "#     # soc = features[0].view(-1, 1)\n",
    "#     y = ltn.Variable(\"y\", features)\n",
    "#     s = ltn.Variable(\"s\", label)\n",
    "#     return Forall([y, s], Implies(Label(y), And(Battery_SOC_Greater_tr1(s), t1(y))), p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predicates for each threshold\n",
    "def Battery_SOC_Greater_tr1(tensor):\n",
    "    return tensor >= tr1.value\n",
    "\n",
    "Battery_SOC_Greater_tr1 = ltn.Predicate(None, Battery_SOC_Greater_tr1)\n",
    "\n",
    "def Battery_SOC_Between_tr1_tr2(tensor):\n",
    "    return ((tensor >= tr2.value) & (tensor < tr1.value)).float()\n",
    "\n",
    "\n",
    "Battery_SOC_Between_tr1_tr2 = ltn.Predicate(None, Battery_SOC_Between_tr1_tr2)\n",
    "\n",
    "\n",
    "def Battery_SOC_Less_tr2(tensor):\n",
    "    return (tensor < tr2.value).float()\n",
    "\n",
    "Battery_SOC_Less_tr2 = ltn.Predicate(None, Battery_SOC_Less_tr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_label(tensor):\n",
    "    if Battery_SOC_Greater_tr1(tensor):\n",
    "        return 'completely covered'\n",
    "    elif Battery_SOC_Between_tr1_tr2(tensor):\n",
    "        return 'covered'\n",
    "    else:\n",
    "        return 'charged'\n",
    "\n",
    "map_to_label = ltn.Function(None, map_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placPred(tensor):\n",
    "    return tensor\n",
    "\n",
    "placPred = ltn.Predicate(None, placPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problems seems to be with how I do the predicates => they seem to need a model parameter if trainable!!!!\n",
    "- for each treshold we should have a NN that predicts it's value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr1.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "# Exists(d,\n",
    "#       Forall([x, y],\n",
    "#             Eq(x, y),\n",
    "#             cond_vars=[x, y, d],\n",
    "#             cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "#             )).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(Label.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        i2 = (labels == 2)\n",
    "        i1 = (labels == 1)\n",
    "        i0 = (labels == 0)\n",
    "\n",
    "        l2 = ltn.Variable(\"l2\", labels[i2] / 2)\n",
    "        l1 = ltn.Variable(\"l1\", labels[i1] / 2)\n",
    "        l0 = ltn.Variable(\"l0\", labels[i0] / 2)\n",
    "        p2 = ltn.Variable(\"p2\", data[i2])\n",
    "        p1 = ltn.Variable(\"p1\", data[i1])\n",
    "        p0 = ltn.Variable(\"p0\", data[i0])\n",
    "    \n",
    "        sat_agg = SatAgg(\n",
    "            Forall(p2, Implies(Battery_SOC_Greater_tr1(p2), placPred(l2)), p=5).value.mean(),\n",
    "            Forall(p1, Implies(Battery_SOC_Between_tr1_tr2(p1), placPred(l1)), p=5).value.mean(),\n",
    "            Forall(p0, Implies(Battery_SOC_Less_tr2(p0), placPred(l0)), p=5).value.mean()\n",
    "        )\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = 1 - sat_agg\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate the loss and update the weights\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {train_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "# Exists(d,\n",
    "#       Forall([x, y],\n",
    "#             Eq(x, y),\n",
    "#             cond_vars=[x, y, d],\n",
    "#             cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "#             )).value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As showed in the example, in order to use a guarded quantification it is enough to specify some condition variables (`cond_vars` parameter) and a\n",
    "condition function (`cond_fn` parameter). In particular, `cond_vars` requires a list of LTN variables, while\n",
    "`cond_fn` requires a function. The function computes a boolean mask, then the mask is used to select the values on which\n",
    "the aggregation has to be computed.\n",
    "\n",
    "In this specific example, the guarded quantification is used for aggregating over pairs of points whose distance is under a certain\n",
    "threshold, specified by variable $d$. All the other pairs of points are not considered during the aggregation.\n",
    "\n",
    "The guarded option is particularly useful to propagate gradients (see notebook on learning) only over a subset of the\n",
    "domains, namely the domains which verifies the condition $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's restart and do the approach diferently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a model that predicts the labels, than from this we will add trainable constants for tresholds \n",
    "Label\n",
    "- charged               52485\n",
    "- covered                6929\n",
    "- completely covered       28\n",
    "\n",
    "For this specific task, LTN uses the following language and grounding:\n",
    "\n",
    "**Domains:**\n",
    "- $feat$, denoting the examples;\n",
    "- $labels$, denoting the class labels.\n",
    "\n",
    "**Variables:**\n",
    "- $x_A, x_B, x_C$ for the examples of classes $A$, $B$, and $C$;\n",
    "- $x$ for all examples;\n",
    "- $D(x_A) = D(x_B) = D(x_C) = D(x) = items$.\n",
    "\n",
    "**Constants:**\n",
    "- $l_A, l_B, l_C$, the labels of classes $A$ (charged), $B$ (covered), $C$ (completely covered), respectively;\n",
    "- $D(l_A) = D(l_B) = D(l_C) = labels$.\n",
    "\n",
    "**Predicates:**\n",
    "- $P(x,l)$ denoting the fact that item $x$ is classified as $l$;\n",
    "- $D_{in}(P) = items, labels$.\n",
    "\n",
    "**Axioms:**\n",
    "\n",
    "- $\\forall x_A P(x_A, l_A)$: all the examples of class $A$ should have label $l_A$;\n",
    "- $\\forall x_B P(x_B, l_B)$: all the examples of class $B$ should have label $l_B$;\n",
    "- $\\forall x_C P(x_C, l_C)$: all the examples of class $C$ should have label $l_C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ds[['WALLBOX_FASTCHARGER_POWER', 'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER', 'POWER_DEMAND', 'POWER_SUPPLY']]\n",
    "target = ds['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: \"charged\" is encoded as 0\n",
      "Original Class: \"completely covered\" is encoded as 1\n",
      "Original Class: \"covered\" is encoded as 2\n"
     ]
    }
   ],
   "source": [
    "# After fitting and transforming the target with LabelEncoder\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)\n",
    "\n",
    "# Print classes and their labels\n",
    "for label, original_class in enumerate(le.classes_):\n",
    "    print(f'Original Class: \"{original_class}\" is encoded as {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we define the constants\n",
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))\n",
    "\n",
    "# we define predicate P\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes=(5, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n",
    "\n",
    "mlp = MLP()\n",
    "# mlp2 = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "# P2 = ltn.Predicate(LogitsToPredicate(mlp2))\n",
    "\n",
    "# we define the connectives, quantifiers, and the SatAgg\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test loader features_train, features_test, target_train, target_test\n",
    "train_loader = DataLoader(features_train, target_train, 64, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Battery_SOC_smaller(tensor, tr):\n",
    "    return tensor <= tr\n",
    "\n",
    "Battery_SOC_smaller = ltn.Predicate(None, Battery_SOC_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Battery_SOC_bigger(tensor, tr):\n",
    "    return tensor > tr\n",
    "\n",
    "Battery_SOC_bigger = ltn.Predicate(None, Battery_SOC_bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns a single value (threshold) given a set of features. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ThresholdModel, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :return: threshold for example x\n",
    "        \"\"\"\n",
    "        x = self.elu(self.linear1(x))\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "\n",
    "# class ThresholdToPredicate(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, threshold_model):\n",
    "#         super(ThresholdToPredicate, self).__init__()\n",
    "#         self.threshold_model = threshold_model\n",
    "\n",
    "#     def forward(self, x, l, training=False):\n",
    "#         threshold = self.threshold_model(x)\n",
    "#         out = (x > threshold).float() * l\n",
    "#         return out\n",
    "    \n",
    "# we define function f\n",
    "model = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))\n",
    "# model2 = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))\n",
    "# TR = ltn.Predicate(ThresholdToPredicate(model))\n",
    "# testm = ltn.Predicate(ThresholdModel(input_size=1, hidden_size=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr1 = ltn.Constant(torch.tensor([80]), trainable=True)\n",
    "# tr2 = ltn.Constant(torch.tensor([40]), trainable=True)\n",
    "# tr3 = ltn.Constant(torch.tensor([15.0]), trainable=True)\n",
    "# tr3 = ltn.Variable(\"tr3\", tr3.value)\n",
    "\n",
    "# tresholds = [ltn.Constant(torch.tensor([i]), trainable=True) for i in range(1)]\n",
    "# tr1v = ltn.Variable(\"tr1\", tr1.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treshold might be maybe found like this: exists a treshold such that for all X in A the labels are only A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working retrival of the 15% treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.05\n",
    "# Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tr - tensor), dim=1))))\n",
    "alpha = 0.001\n",
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tr - tensor), dim=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.1429 | Train Sat 0.930 | Test Sat 0.928 | Train Acc 0.990 | Test Acc 0.990\n",
      "Lower treshold 1: tensor(39.2090, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# we ground the variables with current batch data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m x_A \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_A\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# class A examples\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m x_B \u001b[38;5;241m=\u001b[39m \u001b[43mltn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# class B examples\u001b[39;00m\n\u001b[0;32m     12\u001b[0m x_C \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_C\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# class C examples\u001b[39;00m\n\u001b[0;32m     14\u001b[0m x_A_SOC \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_A_SOC\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# class A examples\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:244\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[1;34m(self, var_label, individuals, add_batch_dim)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m add_batch_dim:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# adds a dimension to transform the input in a sequence of individuals in the case in which it is not\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# already a sequence of individuals but just a tensor with only one dimension\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# the dimension added will be the batch dimension\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# Example: [3, 1, 2] is transformed into [[3], [1], [2]] if individuals has one dimension and add_batch_dim\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# is set to True\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mltn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_var \u001b[38;5;241m=\u001b[39m var_label\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(list(P.parameters()) + list(model.parameters()) + [i.value for i in tresholds], lr=0.001)\n",
    "# optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(list(P.parameters()) + list(model.parameters()), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 1]) # class A examples\n",
    "        tresh1 = model(x_A_SOC)\n",
    "\n",
    "        # actual_tresh1_value = tresh1.value.detach().clone()  # Store the actual value before applying sigmoid\n",
    "        # tr = ltn.Variable(\"tr1\", torch.sigmoid(tresh1.value))\n",
    "\n",
    "        tresh = ltn.Variable(\"tresh\", tresh1.value)\n",
    "        # print(tresh1.value)\n",
    "        # print(Exists(tresh, Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh), p=5), p=1).value.mean())\n",
    "\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True)),\n",
    "         \n",
    "            Exists(tresh, Forall(x_A_SOC, Battery_SOC_smaller2(x_A_SOC, tresh))),\n",
    "           \n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    if epoch % 30 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tr - tensor), dim=1))))\n",
    "# alpha = 0.05\n",
    "# Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.sigmoid(-alpha * (tr - tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Battery_SOC_smaller3 = ltn.Predicate(func=lambda tensor, tr:  torch.sigmoid(tr - tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ThresholdModel2(torch.nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "#         super(ThresholdModel2, self).__init__()\n",
    "#         self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "#         self.fc2 = torch.nn.Linear(hidden_size, 1)\n",
    "#         self.relu = torch.nn.ReLU()  # ReLU activation function\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)  # Apply ReLU after first layer\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu(x)  # Apply ReLU after second layer\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.0651 | Train Sat 0.947 | Test Sat 0.952 \n",
      "Lower treshold 1: tensor(35.2052, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m sat_agg\n\u001b[0;32m     29\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 30\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     32\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\optim\\adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "        \n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 1]) # class A examples\n",
    "\n",
    "        dt = ltn.Variable(\"dt\", data[:, 1]) # class A examples\n",
    "        tresh1 = model2(dt)\n",
    "        # print(dt)\n",
    "        # actual_tresh1_value = tresh1.value.detach().clone()  # Store the actual value before applying sigmoid\n",
    "        # tr = ltn.Variable(\"tr1\", torch.sigmoid(tresh1.value))\n",
    "\n",
    "        tresh = ltn.Variable(\"tresh\", tresh1.value)\n",
    "        # print(model2(x_A_SOC))\n",
    "        # print(Exists(tresh, Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh), p=5), p=1).value.mean())\n",
    "        # print(tresh.value)\n",
    "        sat_agg = SatAgg(    \n",
    "            # there is a treshold such that SOC is smaller than treshold \n",
    "            Exists(tresh, Forall(dt, Battery_SOC_smaller2(dt, tresh))),\n",
    "           \n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 50 epochs of training\n",
    "    if epoch % 30 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f \" %\n",
    "              (epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader)))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing if the treshold on a dataset with gt labels will be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModeln(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns a single value (threshold) given a set of features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ThresholdModeln, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 1)\n",
    "        self.relu = torch.nn.ReLU()  # Add ReLU activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :return: threshold for example x\n",
    "        \"\"\"\n",
    "        x = self.elu(self.linear1(x))\n",
    "        out = self.linear2(x)\n",
    "        out = self.relu(out)  # Apply ReLU activation to ensure non-negative output\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tr - tensor + epsilon), dim=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "Battery_SOC_larger2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tensor - tr + epsilon), dim=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.2207 | Train Sat 0.786 | Test Sat 0.790 | Train Acc 0.941 | Test Acc 0.944\n",
      "Lower treshold 1: tensor(11.9477, grad_fn=<MeanBackward0>) tensor(0.6569)\n",
      "Lower treshold 2: tensor(38.6360, grad_fn=<MeanBackward0>) tensor(0.1439)\n",
      " epoch 30 | loss 0.1584 | Train Sat 0.806 | Test Sat 0.806 | Train Acc 0.951 | Test Acc 0.950\n",
      "Lower treshold 1: tensor(21.8319, grad_fn=<MeanBackward0>) tensor(0.9411)\n",
      "Lower treshold 2: tensor(36.4940, grad_fn=<MeanBackward0>) tensor(0.0230)\n",
      " epoch 60 | loss 0.1575 | Train Sat 0.808 | Test Sat 0.808 | Train Acc 0.951 | Test Acc 0.951\n",
      "Lower treshold 1: tensor(23.6889, grad_fn=<MeanBackward0>) tensor(0.8965)\n",
      "Lower treshold 2: tensor(36.9687, grad_fn=<MeanBackward0>) tensor(0.0465)\n",
      " epoch 90 | loss 0.1583 | Train Sat 0.810 | Test Sat 0.802 | Train Acc 0.952 | Test Acc 0.954\n",
      "Lower treshold 1: tensor(21.6373, grad_fn=<MeanBackward0>) tensor(0.9705)\n",
      "Lower treshold 2: tensor(36.1338, grad_fn=<MeanBackward0>) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(list(P.parameters()) + list(model3.parameters()), lr=0.001)\n",
    "# optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        x_B_SOC = ltn.Variable(\"x_B_SOC\", data[labels == 1][:, 1])\n",
    "\n",
    "        x_C_SOC = ltn.Variable(\"x_C_SOC\", data[labels == 2][:, 1])\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 1])\n",
    "\n",
    "        tresh1 = model3(x_B_SOC)\n",
    "        tresh2 = model3(x_A_SOC)\n",
    "        tresh = ltn.Variable(\"tre1\", tresh1.value)\n",
    "        tresh2 = ltn.Variable(\"tre2\", tresh2.value)\n",
    "        \n",
    "        sat_agg = SatAgg(    \n",
    "            # there is a treshold such that SOC is smaller than treshold \n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True)),\n",
    "            Exists(tresh, Forall(x_B_SOC, Battery_SOC_smaller2(x_B_SOC, tresh), p=5), p=5),\n",
    "            Exists(tresh, Forall(x_C_SOC, Battery_SOC_larger2(x_C_SOC, tresh), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_A_SOC, Battery_SOC_smaller2(x_A_SOC, tresh2), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_C_SOC, Battery_SOC_larger2(x_C_SOC, tresh2), p=5) ,p=5),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 30 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean(), Forall(x_B_SOC, Battery_SOC_smaller(x_B_SOC, tresh)).value.mean())\n",
    "        print(\"Lower treshold 2:\", tresh2.value.mean(), Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh2)).value.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  epoch 0 | loss 0.2207 | Train Sat 0.786 | Test Sat 0.790 | Train Acc 0.941 | Test Acc 0.944\n",
    "# Lower treshold 1: tensor(11.9477, grad_fn=<MeanBackward0>) tensor(0.6569)\n",
    "# Lower treshold 2: tensor(38.6360, grad_fn=<MeanBackward0>) tensor(0.1439)\n",
    "#  epoch 30 | loss 0.1584 | Train Sat 0.806 | Test Sat 0.806 | Train Acc 0.951 | Test Acc 0.950\n",
    "# Lower treshold 1: tensor(21.8319, grad_fn=<MeanBackward0>) tensor(0.9411)\n",
    "# Lower treshold 2: tensor(36.4940, grad_fn=<MeanBackward0>) tensor(0.0230)\n",
    "#  epoch 60 | loss 0.1575 | Train Sat 0.808 | Test Sat 0.808 | Train Acc 0.951 | Test Acc 0.951\n",
    "# Lower treshold 1: tensor(23.6889, grad_fn=<MeanBackward0>) tensor(0.8965)\n",
    "# Lower treshold 2: tensor(36.9687, grad_fn=<MeanBackward0>) tensor(0.0465)\n",
    "#  epoch 90 | loss 0.1583 | Train Sat 0.810 | Test Sat 0.802 | Train Acc 0.952 | Test Acc 0.954\n",
    "# Lower treshold 1: tensor(21.6373, grad_fn=<MeanBackward0>) tensor(0.9705)\n",
    "# Lower treshold 2: tensor(36.1338, grad_fn=<MeanBackward0>) tensor(0.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
