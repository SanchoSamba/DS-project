{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ltn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = s_data[['_time','GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
    "      #  'DEMAND_LIMIT_INDICATOR', \n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'BATTERY_CHARGED_ENERGY', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
    "       'PV_ENERGY'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the labeling function to create the new column \"DRAWN_FROM\"\n",
    "s_data[\"DRAWN_FROM\"] = s_data.apply(label_charging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data_small = s_data.sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = s_data.drop(['_time','DRAWN_FROM', 'BATTERY_DISCHARGE_POWER', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY', 'GARAGE_EXTERNAL_POWER'], axis=1)\n",
    "target = s_data['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAWN_FROM\n",
      "Battery Charged from Grid                          54783\n",
      "Partially Covered by Local Battery                  4457\n",
      "Battery Discharge Stopped due to Battery Health      202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calculate number of points in each class\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor implementation tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Dataset:\n",
    "\n",
    "#   def __init__(self, samples, labels, batch_size = 32):\n",
    "\n",
    "#     self.samples = samples\n",
    "#     self.labels = labels\n",
    "\n",
    "#     self.batch_size = batch_size\n",
    "\n",
    "#     self.length = int(np.ceil(samples.shape[0]/batch_size))\n",
    "\n",
    "#     self.indices = np.arange(samples.shape[0]) \n",
    "\n",
    "#   def __getitem__(self, i):\n",
    "\n",
    "#     i0 = i*self.batch_size\n",
    "#     i1 = min((i + 1)*self.batch_size, self.samples.shape[0])\n",
    "\n",
    "#     index = self.indices[i0:i1]\n",
    "\n",
    "#     return self.samples[index], self.labels[index]\n",
    "\n",
    "#   def __len__(self):\n",
    "#     return self.length\n",
    "\n",
    "#   def shuffle(self):\n",
    "#     self.indices = np.random.permutation(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class SubNetworkTF(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "#         super().__init__()\n",
    "#         ks = (kernel_size, kernel_size)\n",
    "#         self.f = nn.Sequential(\n",
    "#             # Adjust the number of input and output channels\n",
    "#             nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=ks, stride=1, padding=0),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.f(x)\n",
    "\n",
    "# class NetworkTF(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.f = nn.Sequential(\n",
    "#             # The first block takes 1 input channel and produces 16 output channels\n",
    "#             SubNetworkTF(in_channels=1, out_channels=16),\n",
    "#             # The second block takes 16 input channels and produces 64 output channels\n",
    "#             SubNetworkTF(in_channels=16, out_channels=64),\n",
    "\n",
    "#             # Add a convolution layer with kernel size of 4 and 10 output channels\n",
    "#             nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(4, 4), stride=1, padding=0),\n",
    "            \n",
    "#             # Flatten the output of the last convolution layer\n",
    "#             nn.Flatten(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.f(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def fit(model, number_of_epochs, train_data, train_labels, val_data, val_labels):\n",
    "#     # Define the CrossEntropyLoss and SGD optimizer\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.1)  \n",
    "\n",
    "#     # Lists to store training and validation losses\n",
    "#     training_losses = []\n",
    "#     validation_losses = []\n",
    "\n",
    "#     best_model = None\n",
    "#     best_val_loss = float('inf')  # Initialize with a large value\n",
    "\n",
    "#     for epoch in range(number_of_epochs):\n",
    "#         # Set the model to training mode\n",
    "#         model.train()\n",
    "\n",
    "#         # Forward pass\n",
    "#         train_outputs = model(train_data)\n",
    "#         train_loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Set the model to evaluation mode\n",
    "#         model.eval()\n",
    "\n",
    "#         # Forward pass for validation\n",
    "#         with torch.no_grad():\n",
    "#             val_outputs = model(val_data)\n",
    "#             val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "#         # Save training and validation losses\n",
    "#         training_losses.append(train_loss.item())\n",
    "#         validation_losses.append(val_loss.item())\n",
    "\n",
    "#         # Update best model if current validation loss is lower\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             best_model = model\n",
    "\n",
    "#         print(f'Epoch [{epoch + 1}/{number_of_epochs}], '\n",
    "#               f'Training Loss: {train_loss.item():.4f}, '\n",
    "#               f'Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "#     return best_model, training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to convert labels to one-hot encoding\n",
    "# def one_hot_encode(labels, num_classes):\n",
    "#     return F.one_hot(labels, num_classes=num_classes)\n",
    "\n",
    "# def preprocess_data(samples, labels):\n",
    "#     print(labels)\n",
    "#     labels = torch.Tensor(labels)  # Convert labels to PyTorch Tensor\n",
    "#     labels_one_hot = one_hot_encode(labels.long(), num_classes=3)  # Assuming 3 classes\n",
    "#     return torch.Tensor(samples.values), labels_one_hot  # Convert DataFrame to numpy array before converting to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the data into training and validation sets\n",
    "# train_samples, val_samples, train_labels, val_labels = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m val_labels \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(val_labels)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Now you can preprocess the data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m train_samples, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m(train_samples, train_labels)\n\u001b[0;32m     12\u001b[0m val_samples, val_labels \u001b[38;5;241m=\u001b[39m preprocess_data(val_samples, val_labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Instantiate the encoder\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# # Fit and transform the labels\n",
    "# train_labels = encoder.fit_transform(train_labels)\n",
    "# val_labels = encoder.transform(val_labels)\n",
    "\n",
    "# # Now you can preprocess the data\n",
    "# train_samples, train_labels = preprocess_data(train_samples, train_labels)\n",
    "# val_samples, val_labels = preprocess_data(val_samples, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(train_samples, train_labels)\n",
    "# val_dataset = TensorDataset(val_samples, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_model = NetworkTF()\n",
    "# x,y = train_dataset[0]\n",
    "# vx,vy = val_dataset[0]\n",
    "# # y = y.argmax(dim=1)\n",
    "# # vy = vy.argmax(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# best_pytorch_model, pytorch_train_losses, pytorch_val_losses = fit(tf_model, num_epochs, x, y, vx, vy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Tensor Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of the target\n",
    "unique_values = np.unique(en_targ)\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "# target_train = torch.tensor(target_train.to_numpy()).long()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n",
    "# target_test = torch.tensor(target_test.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(4, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "\n",
    "# we define the connectives, quantifiers, and the SatAgg\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = self.batch_size // len(self.unique_labels)\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features_train, features_test, target_train, target_test\n",
    "# create train and test loader\n",
    "train_loader = DataLoader(features_train, target_train, 256, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([43811,   165,  3577], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values of the target and how much there is of each\n",
    "unique_values, counts = np.unique(target_train, return_counts=True)\n",
    "unique_values, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4090 | Train Sat 0.655 | Test Sat 0.660 | Train Acc 0.837 | Test Acc 0.843\n",
      " epoch 20 | loss 0.2712 | Train Sat 0.735 | Test Sat 0.736 | Train Acc 0.919 | Test Acc 0.922\n",
      " epoch 40 | loss 0.2641 | Train Sat 0.747 | Test Sat 0.751 | Train Acc 0.921 | Test Acc 0.922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m x_C \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_C\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# class C examples\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(x_B)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sat_agg \u001b[38;5;241m=\u001b[39m SatAgg(\n\u001b[0;32m     13\u001b[0m     Forall(x_A, P(x_A, l_A, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[1;32m---> 14\u001b[0m     Forall(x_B, \u001b[43mP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[0;32m     15\u001b[0m     Forall(x_C, P(x_C, l_C, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m sat_agg\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:613\u001b[0m, in \u001b[0;36mPredicate.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m proc_objs, output_vars, output_shape \u001b[38;5;241m=\u001b[39m process_ltn_objects(inputs)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# the management of the input is left to the model or the lambda function\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproc_objs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# check if output of predicate contains only truth values, namely values in the range [0., 1.]\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mlogical_and(output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, output \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m), \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 33\u001b[0m, in \u001b[0;36mLogitsToPredicate.forward\u001b[1;34m(self, x, l, training)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, l, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[0;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(probs \u001b[38;5;241m*\u001b[39m l, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 11\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 11\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m     13\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "        # print(x_B)\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a matrix to store the counts\n",
    "class_counts = np.zeros((500, 3))\n",
    "\n",
    "for epoch in range(500):\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        # Count the number of examples in each class\n",
    "        class_counts[epoch, 0] = np.sum(labels == 0)\n",
    "        class_counts[epoch, 1] = np.sum(labels == 1)\n",
    "        class_counts[epoch, 2] = np.sum(labels == 2)\n",
    "    \n",
    "# Convert the counts to a DataFrame\n",
    "df_class_counts = pd.DataFrame(class_counts, columns=['Class A', 'Class B', 'Class C'])\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(df_class_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we tried to again predict the peak shaving, and check for different predicates what is their satisfaction level.\n",
    "- it would make sense that if we have a predicate: SOC <= 20 stop peak shaving, than if the treshold is good (or the rule in general), than the satisfaction of this rule will be high.\n",
    "- This could also allow us to check the relation to the solar panels ? -> if the predicat that includes it does better than that that does not include it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 10% of the dataset \n",
    "data_small = s_data.sample(frac=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_peak_shaving(row):\n",
    "    if row['GARAGE_EXTERNAL_POWER'] >= row['DEMAND_LIMIT']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_small['Peak_Shaving'] = data_small.apply(check_peak_shaving, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds\n",
    "battery_discharge_power_threshold = 0\n",
    "pv_power_threshold = 0.5\n",
    "\n",
    "def adjust_peak_shaving(row):\n",
    "    if row['Peak_Shaving'] == True:\n",
    "        if row['BATTERY_DISCHARGE_POWER'] > battery_discharge_power_threshold or row['PV_POWER'] > pv_power_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small['Peak_Shaving'] = data_small.apply(adjust_peak_shaving, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_time</th>\n",
       "      <th>GARAGE_EXTERNAL_POWER</th>\n",
       "      <th>DEMAND_LIMIT</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "      <th>BATTERY_DISCHARGE_POWER</th>\n",
       "      <th>BATTERY_CHARGED_ENERGY</th>\n",
       "      <th>BATTERY_DISCHARGED_ENERGY</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>PV_ENERGY</th>\n",
       "      <th>Peak_Shaving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>2023-10-31 12:34:00+00:00</td>\n",
       "      <td>1.052765</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>2023-10-08 23:00:00+00:00</td>\n",
       "      <td>1.244171</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56605</th>\n",
       "      <td>2023-11-17 00:43:00+00:00</td>\n",
       "      <td>26.796896</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.422000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>2023-10-30 12:12:00+00:00</td>\n",
       "      <td>49.957039</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.626003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>2.144122</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>2023-10-27 14:37:00+00:00</td>\n",
       "      <td>9.857449</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-0.351000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452726</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>2023-10-23 02:38:00+00:00</td>\n",
       "      <td>1.244171</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.454000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53452</th>\n",
       "      <td>2023-11-14 20:09:00+00:00</td>\n",
       "      <td>5.646513</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49352</th>\n",
       "      <td>2023-11-11 23:48:00+00:00</td>\n",
       "      <td>0.957061</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12276</th>\n",
       "      <td>2023-10-13 20:31:00+00:00</td>\n",
       "      <td>1.244171</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562</th>\n",
       "      <td>2023-11-06 02:19:00+00:00</td>\n",
       "      <td>10.527370</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.181000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _time  GARAGE_EXTERNAL_POWER  DEMAND_LIMIT  \\\n",
       "35762  2023-10-31 12:34:00+00:00               1.052765          50.0   \n",
       "5687   2023-10-08 23:00:00+00:00               1.244171          50.0   \n",
       "56605  2023-11-17 00:43:00+00:00              26.796896          50.0   \n",
       "34300  2023-10-30 12:12:00+00:00              49.957039          50.0   \n",
       "30633  2023-10-27 14:37:00+00:00               9.857449          50.0   \n",
       "...                          ...                    ...           ...   \n",
       "25598  2023-10-23 02:38:00+00:00               1.244171          50.0   \n",
       "53452  2023-11-14 20:09:00+00:00               5.646513          50.0   \n",
       "49352  2023-11-11 23:48:00+00:00               0.957061          50.0   \n",
       "12276  2023-10-13 20:31:00+00:00               1.244171          50.0   \n",
       "41562  2023-11-06 02:19:00+00:00              10.527370          50.0   \n",
       "\n",
       "       BATTERY_SOC  BATTERY_DISCHARGE_POWER  BATTERY_CHARGED_ENERGY  \\\n",
       "35762         40.5                -0.232000                     0.0   \n",
       "5687          40.5                -0.317000                     0.0   \n",
       "56605         41.0                -0.422000                     0.0   \n",
       "34300         21.0                46.626003                     0.0   \n",
       "30633         54.5                -0.351000                     0.0   \n",
       "...            ...                      ...                     ...   \n",
       "25598         41.0                -0.454000                     0.0   \n",
       "53452         40.5                -0.187000                     0.0   \n",
       "49352         40.5                -0.211000                     0.0   \n",
       "12276         41.0                -0.407000                     0.0   \n",
       "41562         40.5                -0.181000                     0.0   \n",
       "\n",
       "       BATTERY_DISCHARGED_ENERGY  PV_POWER  PV_ENERGY  Peak_Shaving  \n",
       "35762                   0.000000  0.912828   0.015625         False  \n",
       "5687                    0.000000  0.009138   0.000000         False  \n",
       "56605                   0.000000  0.003416   0.000000         False  \n",
       "34300                   0.800781  2.144122   0.046875         False  \n",
       "30633                   0.000000  0.452726   0.003906         False  \n",
       "...                          ...       ...        ...           ...  \n",
       "25598                   0.000000  0.008325   0.000000         False  \n",
       "53452                   0.000000  0.007033   0.000000         False  \n",
       "49352                   0.000000  0.007655   0.000000         False  \n",
       "12276                   0.000000  0.008098   0.000000         False  \n",
       "41562                   0.000000  0.006351   0.000000         False  \n",
       "\n",
       "[23777 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_small.drop(['_time','Peak_Shaving','DEMAND_LIMIT', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY'], axis=1)\n",
    "target = data_small['Peak_Shaving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GARAGE_EXTERNAL_POWER</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "      <th>BATTERY_DISCHARGE_POWER</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>PV_ENERGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>1.052765</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56605</th>\n",
       "      <td>26.796896</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.422000</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>49.957039</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.626003</td>\n",
       "      <td>2.144122</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>9.857449</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-0.351000</td>\n",
       "      <td>0.452726</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.454000</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53452</th>\n",
       "      <td>5.646513</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49352</th>\n",
       "      <td>0.957061</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12276</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562</th>\n",
       "      <td>10.527370</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.181000</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GARAGE_EXTERNAL_POWER  BATTERY_SOC  BATTERY_DISCHARGE_POWER  PV_POWER  \\\n",
       "35762               1.052765         40.5                -0.232000  0.912828   \n",
       "5687                1.244171         40.5                -0.317000  0.009138   \n",
       "56605              26.796896         41.0                -0.422000  0.003416   \n",
       "34300              49.957039         21.0                46.626003  2.144122   \n",
       "30633               9.857449         54.5                -0.351000  0.452726   \n",
       "...                      ...          ...                      ...       ...   \n",
       "25598               1.244171         41.0                -0.454000  0.008325   \n",
       "53452               5.646513         40.5                -0.187000  0.007033   \n",
       "49352               0.957061         40.5                -0.211000  0.007655   \n",
       "12276               1.244171         41.0                -0.407000  0.008098   \n",
       "41562              10.527370         40.5                -0.181000  0.006351   \n",
       "\n",
       "       PV_ENERGY  \n",
       "35762   0.015625  \n",
       "5687    0.000000  \n",
       "56605   0.000000  \n",
       "34300   0.046875  \n",
       "30633   0.003906  \n",
       "...          ...  \n",
       "25598   0.000000  \n",
       "53452   0.000000  \n",
       "49352   0.000000  \n",
       "12276   0.000000  \n",
       "41562   0.000000  \n",
       "\n",
       "[23777 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "target_train = torch.tensor(target_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n",
    "target_test = torch.tensor(target_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try first with a simple rule \n",
    "if GARAGE_EXTERNAL_POWER > DEMAND_LIMIT and SOC >= 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "# we define predicate A\n",
    "class ModelA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelA, self).__init__()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.layer1 = torch.nn.Linear(5, 16)  \n",
    "        self.layer2 = torch.nn.Linear(16, 16)\n",
    "        self.layer3 = torch.nn.Linear(16, 1)\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.layer1(x))\n",
    "        x = self.elu(self.layer2(x))\n",
    "        return self.sigmoid(self.layer3(x))\n",
    "\n",
    "\n",
    "A = ltn.Predicate(ModelA())\n",
    "\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# this is a standard PyTorch DataLoader to load the dataset for the training and testing of the model\n",
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "\n",
    "# define metrics for evaluation of the model\n",
    "\n",
    "# it computes the overall satisfaction level on the knowledge base using the given data loader (train or test)\n",
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[torch.nonzero(labels)])  # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\",\n",
    "                               data[torch.nonzero(torch.logical_not(labels))])  # negative examples\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = A.model(data).detach().numpy()\n",
    "        predictions = np.where(predictions > 0.5, 1., 0.).flatten()\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n",
    "\n",
    "# create train and test loader, 50 points each\n",
    "# batch size is 64, meaning there is only one batch for epoch\n",
    "train_loader = DataLoader(features_train, target_train, 1024, True)\n",
    "test_loader = DataLoader(features_test, target_test, 1024, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def P(tensor):\n",
    "# #     print(tensor)\n",
    "# #     external_power, demand_limit, soc = tensor\n",
    "# #     return (external_power > demand_limit) & (soc >= 15)\n",
    "# def P(tensor):\n",
    "#     # print(tensor)\n",
    "#     external_power, soc = tensor.t()  # transpose the tensor\n",
    "#     return external_power > 50\n",
    "#     # return (external_power < demand_limit)\n",
    "#     # return (external_power > demand_limit) & (soc >= 15)\n",
    "\n",
    "# # Wrap the predicate in an LTN Predicate\n",
    "# P = ltn.Predicate(None, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Q(tensor):\n",
    "#     return tensor >= 0.5  # returns True if p_shav is True\n",
    "\n",
    "# # Wrap the predicate in an LTN Predicate\n",
    "# Q = ltn.Predicate(None, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soc_tensor = torch.tensor(s_data['BATTERY_SOC'].values, dtype=torch.float32)\n",
    "# external_power_tensor = torch.tensor(s_data['GARAGE_EXTERNAL_POWER'].values, dtype=torch.float32)\n",
    "# p_shav = torch.tensor(s_data['Peak_Shaving'].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# def phi(external_power_tensor, soc_tensor, p_shav):\n",
    "#     # Stack the tensors along the last dimension to create a single tensor\n",
    "#     data = torch.stack([external_power_tensor, soc_tensor], dim=-1)\n",
    "\n",
    "#     # Create a variable that represents the data\n",
    "#     p = ltn.Variable(\"p\", data)\n",
    "#     q = ltn.Variable(\"q\", p_shav)\n",
    "\n",
    "#     # Return the satisfaction degree of the formula\n",
    "#     return Forall(p, Implies(P(p), Q(q))).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.5533 | Train Sat 0.583 | Test Sat 0.583 | Train Acc 0.811 | Test Acc 0.812\n",
      " epoch 1 | loss 0.3595 | Train Sat 0.680 | Test Sat 0.685 | Train Acc 0.878 | Test Acc 0.892\n",
      " epoch 2 | loss 0.2965 | Train Sat 0.722 | Test Sat 0.725 | Train Acc 0.898 | Test Acc 0.912\n",
      " epoch 3 | loss 0.2715 | Train Sat 0.734 | Test Sat 0.749 | Train Acc 0.914 | Test Acc 0.925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m      6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# we ground the variables with current batch data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 43\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle:\n\u001b[0;32m     41\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(batch_indices)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[batch_indices]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 1 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GARAGE_EXTERNAL_POWER</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "      <th>BATTERY_DISCHARGE_POWER</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>PV_ENERGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>1.052765</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56605</th>\n",
       "      <td>26.796896</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.422000</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>49.957039</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.626003</td>\n",
       "      <td>2.144122</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>9.857449</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-0.351000</td>\n",
       "      <td>0.452726</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25598</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.454000</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53452</th>\n",
       "      <td>5.646513</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49352</th>\n",
       "      <td>0.957061</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12276</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562</th>\n",
       "      <td>10.527370</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.181000</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23777 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GARAGE_EXTERNAL_POWER  BATTERY_SOC  BATTERY_DISCHARGE_POWER  PV_POWER  \\\n",
       "35762               1.052765         40.5                -0.232000  0.912828   \n",
       "5687                1.244171         40.5                -0.317000  0.009138   \n",
       "56605              26.796896         41.0                -0.422000  0.003416   \n",
       "34300              49.957039         21.0                46.626003  2.144122   \n",
       "30633               9.857449         54.5                -0.351000  0.452726   \n",
       "...                      ...          ...                      ...       ...   \n",
       "25598               1.244171         41.0                -0.454000  0.008325   \n",
       "53452               5.646513         40.5                -0.187000  0.007033   \n",
       "49352               0.957061         40.5                -0.211000  0.007655   \n",
       "12276               1.244171         41.0                -0.407000  0.008098   \n",
       "41562              10.527370         40.5                -0.181000  0.006351   \n",
       "\n",
       "       PV_ENERGY  \n",
       "35762   0.015625  \n",
       "5687    0.000000  \n",
       "56605   0.000000  \n",
       "34300   0.046875  \n",
       "30633   0.003906  \n",
       "...          ...  \n",
       "25598   0.000000  \n",
       "53452   0.000000  \n",
       "49352   0.000000  \n",
       "12276   0.000000  \n",
       "41562   0.000000  \n",
       "\n",
       "[23777 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axioms\n",
    "\n",
    "- for every instance if peak shaving is true than Battery_SOC > 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "\n",
    "def PeakShaving(tensor):\n",
    "    return tensor >= 0.5  # returns True if peak shaving is True\n",
    "\n",
    "PeakShaving = ltn.Predicate(None, PeakShaving)\n",
    "\n",
    "def Battery_SOC_Greater_15(tensor):\n",
    "    return tensor > 35  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_Greater_15 = ltn.Predicate(None, Battery_SOC_Greater_15)\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 45  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "\n",
    "def phi(features, label):\n",
    "   \n",
    "    label = label.view(-1, 1)\n",
    "    sc = features[1].view(-1,1)\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall([y, s], Implies(PeakShaving(y), And(Battery_SOC_Greater_15(s), Battery_SOC_small(s))), p=5)\n",
    "\n",
    "\n",
    "\n",
    "# lets check the satisfaction for the rule that\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def phi2(features, label):\n",
    "#     label = label.view(-1, 1)\n",
    "#     sc = features[1].view(-1,1)\n",
    "\n",
    "#     y = ltn.Variable(\"y\", label)\n",
    "\n",
    "#     # if there is peak shaving both \n",
    "    # return Forall()\n",
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could be interesting is more general rules, that don't require the tresholds\n",
    "- for all x if peak shaving than energy is given from both sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "\n",
    "def phiComp(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #batery power\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([y, b, p], Implies(PeakShaving(y), And(gives_energy(b), gives_energy(p))), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "def gets_charged(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor < 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "gets_charged = ltn.Predicate(None, gets_charged)\n",
    "\n",
    "def phit2(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #batery power\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    # y = ltn.Variable(\"y\", label)\n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([b, p], Implies(gives_energy(p), gives_energy(b)), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7605)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7875)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phiComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4689)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(train_loader, phit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelP2(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ModelP2, self).__init__()\n",
    "#         self.elu = torch.nn.ELU()\n",
    "#         self.sigmoid = torch.nn.Sigmoid()\n",
    "#         self.dense1 = torch.nn.Linear(3, 5)\n",
    "#         self.dense2 = torch.nn.Linear(5, 1) # returns one value in [0,1]\n",
    "\n",
    "#         # Add thresholds as parameters\n",
    "#         self.tr1 = torch.nn.Parameter(torch.tensor([0.]))\n",
    "#         self.tr2 = torch.nn.Parameter(torch.tensor([0.]))\n",
    "#         self.tr3 = torch.nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.elu(self.dense1(x))\n",
    "#         x = self.sigmoid(self.dense2(x))\n",
    "\n",
    "#         # Apply thresholds\n",
    "#         x = torch.where(x > self.tr1, torch.tensor([1.]), x)\n",
    "#         x = torch.where((x > self.tr2) & (x <= self.tr1), torch.tensor([0.5]), x)\n",
    "#         x = torch.where(x <= self.tr2, torch.tensor([0.]), x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# modelP2 = ModelP2()\n",
    "# P2 = ltn.Predicate(model=modelP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelP2 = ModelP2()\n",
    "# P2 = ltn.Predicate(model=modelP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr1 = ltn.Constant(torch.tensor([0]), trainable=True)\n",
    "# tr2 = ltn.Constant(torch.tensor([0]), trainable=True)\n",
    "# tr3 = ltn.Constant(torch.tensor([0]), trainable=True)\n",
    "\n",
    "# trl = ltn.Variable('trl', torch.stack([tr1.value, tr2.value, tr3.value]))\n",
    "\n",
    "\n",
    "# def phi_tres(features, label):\n",
    "#     label = label.view(-1, 1)\n",
    "#     sc = features[1].view(-1,1)\n",
    "#     y = ltn.Variable(\"y\", label)\n",
    "#     s = ltn.Variable(\"s\", sc)\n",
    "#     t = ltn.Variable(\"t\", tresholds)\n",
    "#     return Forall([y, s, t], Implies(PeakShaving(y), And(Battery_SOC_Greater_15(s), Battery_SOC_small(s), s > t)), p=5)\n",
    "\n",
    "# def phi_tres():\n",
    "#     t = ltn.Variable(\"t\", torch.stack([i.value for i in tresholds.values()]))\n",
    "#     return Forall(t, Implies(C(p), S(p)), p=5).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = P2(trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.2227 | Train Sat 0.780 | Test Sat 0.777 | Train Acc 0.948 | Test Acc 0.943 | Phi Sat 0.488\n",
      " epoch 20 | loss 0.2127 | Train Sat 0.783 | Test Sat 0.785 | Train Acc 0.947 | Test Acc 0.948 | Phi Sat 0.490\n",
      " epoch 40 | loss 0.2116 | Train Sat 0.786 | Test Sat 0.785 | Train Acc 0.949 | Test Acc 0.950 | Phi Sat 0.486\n",
      " epoch 60 | loss 0.2108 | Train Sat 0.790 | Test Sat 0.793 | Train Acc 0.950 | Test Acc 0.949 | Phi Sat 0.489\n",
      " epoch 80 | loss 0.2103 | Train Sat 0.791 | Test Sat 0.784 | Train Acc 0.951 | Test Acc 0.946 | Phi Sat 0.484\n",
      " epoch 100 | loss 0.2067 | Train Sat 0.794 | Test Sat 0.793 | Train Acc 0.952 | Test Acc 0.952 | Phi Sat 0.490\n",
      " epoch 120 | loss 0.2109 | Train Sat 0.793 | Test Sat 0.789 | Train Acc 0.949 | Test Acc 0.953 | Phi Sat 0.488\n",
      " epoch 140 | loss 0.2022 | Train Sat 0.798 | Test Sat 0.790 | Train Acc 0.952 | Test Acc 0.949 | Phi Sat 0.479\n",
      " epoch 160 | loss 0.2045 | Train Sat 0.795 | Test Sat 0.799 | Train Acc 0.952 | Test Acc 0.949 | Phi Sat 0.487\n",
      " epoch 180 | loss 0.2029 | Train Sat 0.795 | Test Sat 0.796 | Train Acc 0.952 | Test Acc 0.949 | Phi Sat 0.484\n",
      " epoch 200 | loss 0.2021 | Train Sat 0.798 | Test Sat 0.795 | Train Acc 0.954 | Test Acc 0.951 | Phi Sat 0.488\n",
      " epoch 220 | loss 0.2027 | Train Sat 0.796 | Test Sat 0.794 | Train Acc 0.954 | Test Acc 0.948 | Phi Sat 0.488\n",
      " epoch 240 | loss 0.2032 | Train Sat 0.798 | Test Sat 0.793 | Train Acc 0.953 | Test Acc 0.948 | Phi Sat 0.484\n",
      " epoch 260 | loss 0.2007 | Train Sat 0.801 | Test Sat 0.796 | Train Acc 0.953 | Test Acc 0.951 | Phi Sat 0.485\n",
      " epoch 280 | loss 0.2033 | Train Sat 0.803 | Test Sat 0.796 | Train Acc 0.954 | Test Acc 0.951 | Phi Sat 0.485\n",
      " epoch 300 | loss 0.1968 | Train Sat 0.800 | Test Sat 0.798 | Train Acc 0.952 | Test Acc 0.952 | Phi Sat 0.486\n",
      " epoch 320 | loss 0.1972 | Train Sat 0.802 | Test Sat 0.799 | Train Acc 0.955 | Test Acc 0.953 | Phi Sat 0.481\n",
      " epoch 340 | loss 0.1974 | Train Sat 0.800 | Test Sat 0.794 | Train Acc 0.952 | Test Acc 0.950 | Phi Sat 0.486\n",
      " epoch 360 | loss 0.1930 | Train Sat 0.804 | Test Sat 0.813 | Train Acc 0.954 | Test Acc 0.955 | Phi Sat 0.485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m      7\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# we ground the variables with current batch data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 43\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle:\n\u001b[0;32m     41\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(batch_indices)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[batch_indices], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# params = list(A.parameters())\n",
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        # p_shav = labels\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A))),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f | Phi Sat %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader), compute_sat_level_phi(test_loader, phit2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for now: \n",
    "- check whith a more complicated new rule how does the satisfaction work \n",
    "\n",
    "Idea:\n",
    "- to learn the treshold we need to save them as variables and create another Predicate to optimze them. But what do we base the optimization on? \n",
    "\n",
    "What can we use for loss? Assuming we want to learn tresholds, what would we use to validate how good we do on the data? \n",
    "- Maybe based on my simple labeled peak shaving? -- For which values is the peak shaving true. Should this be done with another NN model? I guess we save the tresholds as predicates, similarly as I did with Battery_SOC_Greater_15, but the treshold has to be learnable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that guesses peak shaving based on the ground truth\n",
    "\n",
    "For what SOC\n",
    "- e-cars charging is completely covered by the local battery\n",
    "- e-cars charging power is covered by local battery.\n",
    "- local battery is charged from the grid.\n",
    "- Battery discharging is stopped due to battery health\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"POWER_DEMAND\"] = ds[\"WALLBOX_1_POWER\"] + ds[\"WALLBOX_2_POWER\"] + ds[\"WALLBOX_3_POWER\"] + ds[\"WALLBOX_A_POWER\"] + ds[\"WALLBOX_B_POWER\"] + ds[\"WALLBOX_C_POWER\"] + ds[\"WALLBOX_FASTCHARGER_POWER\"]\n",
    "ds[\"POWER_SUPPLY\"] = ds[\"GARAGE_EXTERNAL_POWER\"] + ds[\"PV_POWER\"] + ds[\"BATTERY_DISCHARGE_POWER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-cars charging is completely covered by the local battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does 'BATTERY_DISCHARGE_POWER' ever cover 100% of 'POWER_SUPPLY'? True\n"
     ]
    }
   ],
   "source": [
    "is_covered_prc = ((ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"]) >= 0.98).any()\n",
    "\n",
    "print(f\"Does 'BATTERY_DISCHARGE_POWER' ever cover 100% of 'POWER_SUPPLY'? {is_covered_prc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52480"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52504"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.95:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] > 0.05:\n",
    "        return \"covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] < 0:\n",
    "        return \"charged\"\n",
    "    else:\n",
    "        return \"stopped\"\n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "charged               52479\n",
       "covered                6927\n",
       "completely covered       27\n",
       "stopped                   9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.51:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] > 0.02:\n",
    "        return \"covered\"\n",
    "    else:\n",
    "        return \"charged\"\n",
    "    \n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "charged               52485\n",
       "covered                6779\n",
       "completely covered      178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that, we can try to optimize tresholds for SOC so that they help us predict the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
