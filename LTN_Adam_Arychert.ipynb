{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ltn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = s_data[['_time','GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
    "      #  'DEMAND_LIMIT_INDICATOR', \n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'BATTERY_CHARGED_ENERGY', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
    "       'PV_ENERGY'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the labeling function to create the new column \"DRAWN_FROM\"\n",
    "s_data[\"DRAWN_FROM\"] = s_data.apply(label_charging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data_small = s_data.sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = s_data.drop(['_time','DRAWN_FROM', 'BATTERY_DISCHARGE_POWER', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY', 'GARAGE_EXTERNAL_POWER'], axis=1)\n",
    "target = s_data['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAWN_FROM\n",
      "Battery Charged from Grid                          54783\n",
      "Partially Covered by Local Battery                  4457\n",
      "Battery Discharge Stopped due to Battery Health      202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calculate number of points in each class\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Tensor Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of the target\n",
    "unique_values = np.unique(en_targ)\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(4, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "\n",
    "# we define the connectives, quantifiers, and the SatAgg\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = self.batch_size // len(self.unique_labels)\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(features_train, target_train, 256, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([43811,   165,  3577], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values of the target and how much there is of each\n",
    "unique_values, counts = np.unique(target_train, return_counts=True)\n",
    "unique_values, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4108 | Train Sat 0.653 | Test Sat 0.655 | Train Acc 0.842 | Test Acc 0.841\n",
      " epoch 20 | loss 0.2629 | Train Sat 0.739 | Test Sat 0.750 | Train Acc 0.920 | Test Acc 0.922\n",
      " epoch 40 | loss 0.2582 | Train Sat 0.742 | Test Sat 0.751 | Train Acc 0.919 | Test Acc 0.927\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(60):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "        # print(x_B)\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def labEq2(tensor):\n",
    "    return tensor == 2  \n",
    "\n",
    "labEq2 = ltn.Predicate(None, labEq2)\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 10  # returns True if Battery_SOC > 10\n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "\n",
    "def phi(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    sc = features[1].view(-1,1)\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall(s, Implies(Battery_SOC_small(s), labEq2(y)), p=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        labels = torch.tensor(labels)\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8571)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we tried to again predict the peak shaving, and check for different predicates what is their satisfaction level.\n",
    "- it would make sense that if we have a predicate: SOC <= 20 stop peak shaving, than if the treshold is good (or the rule in general), than the satisfaction of this rule will be high.\n",
    "- This could also allow us to check the relation to the solar panels ? -> if the predicat that includes it does better than that that does not include it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 10% of the dataset \n",
    "data_small = s_data.sample(frac=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_peak_shaving(row):\n",
    "    if row['GARAGE_EXTERNAL_POWER'] >= row['DEMAND_LIMIT']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_small['Peak_Shaving'] = data_small.apply(check_peak_shaving, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thresholds\n",
    "battery_discharge_power_threshold = 0\n",
    "pv_power_threshold = 0.5\n",
    "\n",
    "def adjust_peak_shaving(row):\n",
    "    if row['Peak_Shaving'] == True:\n",
    "        if row['BATTERY_DISCHARGE_POWER'] > battery_discharge_power_threshold or row['PV_POWER'] > pv_power_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small['Peak_Shaving'] = data_small.apply(adjust_peak_shaving, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_small.drop(['_time','Peak_Shaving','DEMAND_LIMIT', 'BATTERY_CHARGED_ENERGY',  'BATTERY_DISCHARGED_ENERGY'], axis=1)\n",
    "target = data_small['Peak_Shaving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'DRAWN_FROM' column and transform it\n",
    "features['DRAWN_FROM'] = le.fit_transform(features['DRAWN_FROM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GARAGE_EXTERNAL_POWER</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "      <th>BATTERY_DISCHARGE_POWER</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>PV_ENERGY</th>\n",
       "      <th>DRAWN_FROM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>1.052765</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56605</th>\n",
       "      <td>26.796896</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.422000</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>49.957039</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.626003</td>\n",
       "      <td>2.144122</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>9.857449</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-0.351000</td>\n",
       "      <td>0.452726</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53401</th>\n",
       "      <td>5.742216</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>6.316434</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.498000</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>13.589869</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.449000</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56156</th>\n",
       "      <td>50.148445</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-10.146001</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47893</th>\n",
       "      <td>4.689482</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.223000</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GARAGE_EXTERNAL_POWER  BATTERY_SOC  BATTERY_DISCHARGE_POWER  PV_POWER  \\\n",
       "35762               1.052765         40.5                -0.232000  0.912828   \n",
       "5687                1.244171         40.5                -0.317000  0.009138   \n",
       "56605              26.796896         41.0                -0.422000  0.003416   \n",
       "34300              49.957039         21.0                46.626003  2.144122   \n",
       "30633               9.857449         54.5                -0.351000  0.452726   \n",
       "...                      ...          ...                      ...       ...   \n",
       "53401               5.742216         40.5                -0.225000  0.007116   \n",
       "19531               6.316434         40.5                -0.498000  0.007033   \n",
       "8130               13.589869         41.0                -0.449000  0.003036   \n",
       "56156              50.148445         33.0               -10.146001 -0.002565   \n",
       "47893               4.689482         40.5                -0.223000  0.007200   \n",
       "\n",
       "       PV_ENERGY  DRAWN_FROM  \n",
       "35762   0.015625           0  \n",
       "5687    0.000000           0  \n",
       "56605   0.000000           0  \n",
       "34300   0.046875           0  \n",
       "30633   0.003906           0  \n",
       "...          ...         ...  \n",
       "53401   0.000000           0  \n",
       "19531   0.000000           0  \n",
       "8130    0.000000           0  \n",
       "56156   0.000000           2  \n",
       "47893   0.000000           0  \n",
       "\n",
       "[58848 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "target_train = torch.tensor(target_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n",
    "target_test = torch.tensor(target_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try first with a simple rule \n",
    "if GARAGE_EXTERNAL_POWER > DEMAND_LIMIT and SOC >= 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "# we define predicate A\n",
    "class ModelA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelA, self).__init__()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.layer1 = torch.nn.Linear(6, 16)  \n",
    "        self.layer2 = torch.nn.Linear(16, 16)\n",
    "        self.layer3 = torch.nn.Linear(16, 1)\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.layer1(x))\n",
    "        x = self.elu(self.layer2(x))\n",
    "        return self.sigmoid(self.layer3(x))\n",
    "\n",
    "\n",
    "A = ltn.Predicate(ModelA())\n",
    "\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# this is a standard PyTorch DataLoader to load the dataset for the training and testing of the model\n",
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "\n",
    "# define metrics for evaluation of the model\n",
    "\n",
    "# it computes the overall satisfaction level on the knowledge base using the given data loader (train or test)\n",
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[torch.nonzero(labels)])  # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\",\n",
    "                               data[torch.nonzero(torch.logical_not(labels))])  # negative examples\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = A.model(data).detach().numpy()\n",
    "        predictions = np.where(predictions > 0.5, 1., 0.).flatten()\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n",
    "\n",
    "# create train and test loader, 50 points each\n",
    "# batch size is 64, meaning there is only one batch for epoch\n",
    "train_loader = DataLoader(features_train, target_train, 1024, True)\n",
    "test_loader = DataLoader(features_test, target_test, 1024, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A)))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 1 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axioms that are tried\n",
    "\n",
    "- for every instance if peak shaving is true than Battery_SOC > 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GARAGE_EXTERNAL_POWER</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "      <th>BATTERY_DISCHARGE_POWER</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>PV_ENERGY</th>\n",
       "      <th>DRAWN_FROM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>1.052765</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.912828</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.244171</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56605</th>\n",
       "      <td>26.796896</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.422000</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>49.957039</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.626003</td>\n",
       "      <td>2.144122</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>9.857449</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-0.351000</td>\n",
       "      <td>0.452726</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53401</th>\n",
       "      <td>5.742216</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>6.316434</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.498000</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>13.589869</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.449000</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56156</th>\n",
       "      <td>50.148445</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-10.146001</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47893</th>\n",
       "      <td>4.689482</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-0.223000</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GARAGE_EXTERNAL_POWER  BATTERY_SOC  BATTERY_DISCHARGE_POWER  PV_POWER  \\\n",
       "35762               1.052765         40.5                -0.232000  0.912828   \n",
       "5687                1.244171         40.5                -0.317000  0.009138   \n",
       "56605              26.796896         41.0                -0.422000  0.003416   \n",
       "34300              49.957039         21.0                46.626003  2.144122   \n",
       "30633               9.857449         54.5                -0.351000  0.452726   \n",
       "...                      ...          ...                      ...       ...   \n",
       "53401               5.742216         40.5                -0.225000  0.007116   \n",
       "19531               6.316434         40.5                -0.498000  0.007033   \n",
       "8130               13.589869         41.0                -0.449000  0.003036   \n",
       "56156              50.148445         33.0               -10.146001 -0.002565   \n",
       "47893               4.689482         40.5                -0.223000  0.007200   \n",
       "\n",
       "       PV_ENERGY  DRAWN_FROM  \n",
       "35762   0.015625           0  \n",
       "5687    0.000000           0  \n",
       "56605   0.000000           0  \n",
       "34300   0.046875           0  \n",
       "30633   0.003906           0  \n",
       "...          ...         ...  \n",
       "53401   0.000000           0  \n",
       "19531   0.000000           0  \n",
       "8130    0.000000           0  \n",
       "56156   0.000000           2  \n",
       "47893   0.000000           0  \n",
       "\n",
       "[58848 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARAGE_EXTERNAL_POWER > 50\n",
    "\n",
    "def P(tensor):\n",
    "    return tensor >= 50\n",
    "\n",
    "# Wrap the predicate in an LTN Predicate\n",
    "P = ltn.Predicate(None, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak shaving is True\n",
    "def Q(tensor):\n",
    "    return tensor >= 0.5  # returns True if p_shav is True\n",
    "\n",
    "# Wrap the predicate in an LTN Predicate\n",
    "Q = ltn.Predicate(None, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phi(features, labels):\n",
    "\n",
    "    features = features[0].view(-1, 1)\n",
    "    labels = labels.view(-1, 1)\n",
    "    # Create a variable that represents the data\n",
    "    p = ltn.Variable(\"p\", features)\n",
    "    q = ltn.Variable(\"q\", labels)\n",
    "\n",
    "\n",
    "    # Return the satisfaction degree of the formula\n",
    "\n",
    "    return Forall(p, Implies(P(p), Q(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9926)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "\n",
    "def PeakShaving(tensor):\n",
    "    return tensor >= 0.5  # returns True if peak shaving is True\n",
    "\n",
    "PeakShaving = ltn.Predicate(None, PeakShaving)\n",
    "\n",
    "def Battery_SOC_Greater_15(tensor):\n",
    "    return tensor > 35  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_Greater_15 = ltn.Predicate(None, Battery_SOC_Greater_15)\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 45  # returns True if Battery_SOC > 15\n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "\n",
    "def phi(features, label):\n",
    "   \n",
    "    label = label.view(-1, 1)\n",
    "    sc = features[1].view(-1,1)\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall([y, s], Implies(PeakShaving(y), And(Battery_SOC_Greater_15(s), Battery_SOC_small(s))), p=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7524)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could be interesting is more general rules, that don't require the tresholds\n",
    "- for all x if peak shaving than energy is given from both sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "\n",
    "def phiComp(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #power plant power\n",
    "    # x = ltn.Variable(\"x\", features)\n",
    "    y = ltn.Variable(\"y\", label)\n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([y, b, p], Implies(PeakShaving(y), And(gives_energy(b), gives_energy(p))), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7871)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(test_loader, phiComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy comes from the power plant and the battery\n",
    "def gives_energy(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor > 0\n",
    "\n",
    "def gets_charged(tensor):\n",
    "    # print(tensor)\n",
    "    return tensor < 0\n",
    "\n",
    "gives_energy = ltn.Predicate(None, gives_energy)\n",
    "gets_charged = ltn.Predicate(None, gets_charged)\n",
    "\n",
    "def phit2(features, label):\n",
    "    label = label.view(-1, 1)\n",
    "    bp = features[2].view(-1,1) #batery power\n",
    "    pp = features[3].view(-1,1) #batery power\n",
    "  \n",
    "    b = ltn.Variable(\"b\", bp)\n",
    "    p = ltn.Variable(\"p\", pp)\n",
    "    return Forall([b, p], Implies(gives_energy(p), gives_energy(b)), p=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4665)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(train_loader, phit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.3080 | Train Sat 0.741 | Test Sat 0.739 | Train Acc 0.918 | Test Acc 0.923 | Phi Sat 0.487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# we print metrics every 20 epochs of training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m | loss \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m | Train Sat \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | Test Sat \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | Train Acc \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | Test Acc \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m | Phi Sat \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m           \u001b[38;5;241m%\u001b[39m(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n\u001b[1;32m---> 27\u001b[0m                 compute_accuracy(train_loader), compute_accuracy(test_loader), \u001b[43mcompute_sat_level_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphit2\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m, in \u001b[0;36mcompute_sat_level_phi\u001b[1;34m(loader, phi)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(features, labels):\n\u001b[1;32m----> 5\u001b[0m         sat_values\u001b[38;5;241m.\u001b[39mappend(\u001b[43mphi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m      6\u001b[0m mean_sat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(sat_values))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_sat\n",
      "Cell \u001b[1;32mIn[81], line 20\u001b[0m, in \u001b[0;36mphit2\u001b[1;34m(features, label)\u001b[0m\n\u001b[0;32m     18\u001b[0m b \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, bp)\n\u001b[0;32m     19\u001b[0m p \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m, pp)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Forall([b, p], Implies(gives_energy(p), \u001b[43mgives_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:610\u001b[0m, in \u001b[0;36mPredicate.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, LTNObject) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs):\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be a tuple of LTNObject, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m([\u001b[38;5;28mtype\u001b[39m(i)\n\u001b[0;32m    608\u001b[0m                                                                                               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]))\n\u001b[1;32m--> 610\u001b[0m proc_objs, output_vars, output_shape \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_ltn_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# the management of the input is left to the model or the lambda function\u001b[39;00m\n\u001b[0;32m    613\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m[o\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m proc_objs], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:321\u001b[0m, in \u001b[0;36mprocess_ltn_objects\u001b[1;34m(objects)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# permute the dimensions of the object in such a way the shapes of the processed objects is the same\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# the shape is computed based on the order in which the variables are found at the beginning of this function\u001b[39;00m\n\u001b[0;32m    320\u001b[0m dims_permutation \u001b[38;5;241m=\u001b[39m [vars_in_obj\u001b[38;5;241m.\u001b[39mindex(var) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vars_in_obj), \u001b[38;5;28mlen\u001b[39m(o\u001b[38;5;241m.\u001b[39mshape())))\n\u001b[1;32m--> 321\u001b[0m o\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims_permutation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# this flats the batch dimension of the processed LTN object if the flat is set to True\u001b[39;00m\n\u001b[0;32m    324\u001b[0m flatten_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(o\u001b[38;5;241m.\u001b[39mshape()[\u001b[38;5;28mlen\u001b[39m(vars_in_obj)::])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "\n",
    "# training of the predicate A using a loss containing the satisfaction level of the knowledge base\n",
    "# the objective it to maximize the satisfaction level of the knowledge base\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels==1]) # positive examples\n",
    "        x_not_A = ltn.Variable(\"x_not_A\", data[labels==0]) # negative examples\n",
    "        # p_shav = labels\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, A(x_A)),\n",
    "            Forall(x_not_A, Not(A(x_not_A))),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f | Phi Sat %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader), compute_sat_level_phi(test_loader, phit2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for now: \n",
    "- check whith a more complicated new rule how does the satisfaction work \n",
    "\n",
    "Idea:\n",
    "- to learn the treshold we need to save them as variables and create another Predicate to optimze them. But what do we base the optimization on? \n",
    "\n",
    "What can we use for loss? Assuming we want to learn tresholds, what would we use to validate how good we do on the data? \n",
    "- Maybe based on my simple labeled peak shaving? -- For which values is the peak shaving true. Should this be done with another NN model? I guess we save the tresholds as predicates, similarly as I did with Battery_SOC_Greater_15, but the treshold has to be learnable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that guesses peak shaving based on the ground truth\n",
    "\n",
    "For what SOC\n",
    "- e-cars charging is completely covered by the local battery\n",
    "- e-cars charging power is covered by local battery.\n",
    "- local battery is charged from the grid.\n",
    "- Battery discharging is stopped due to battery health\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"POWER_DEMAND\"] = ds[\"WALLBOX_1_POWER\"] + ds[\"WALLBOX_2_POWER\"] + ds[\"WALLBOX_3_POWER\"] + ds[\"WALLBOX_A_POWER\"] + ds[\"WALLBOX_B_POWER\"] + ds[\"WALLBOX_C_POWER\"] + ds[\"WALLBOX_FASTCHARGER_POWER\"]\n",
    "ds[\"POWER_SUPPLY\"] = ds[\"GARAGE_EXTERNAL_POWER\"] + ds[\"PV_POWER\"] + ds[\"BATTERY_DISCHARGE_POWER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-cars charging is completely covered by the local battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does 'BATTERY_DISCHARGE_POWER' ever cover 100% of 'POWER_SUPPLY'? True\n"
     ]
    }
   ],
   "source": [
    "is_covered_prc = ((ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"]) >= 0.98).any()\n",
    "\n",
    "print(f\"Does 'BATTERY_DISCHARGE_POWER' ever cover 100% of 'POWER_SUPPLY'? {is_covered_prc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52480"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] / ds[\"POWER_SUPPLY\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[ds[\"BATTERY_DISCHARGE_POWER\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.95:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] > 0.05:\n",
    "        return \"covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] < 0:\n",
    "        return \"charged\"\n",
    "    else:\n",
    "        return \"stopped\"\n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "charged               52479\n",
       "covered                6927\n",
       "completely covered       27\n",
       "stopped                   9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_row(row):\n",
    "    if row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] >= 0.9:\n",
    "        return \"completely covered\"\n",
    "    elif row[\"BATTERY_DISCHARGE_POWER\"] / row[\"POWER_SUPPLY\"] > 0 or row[\"BATTERY_DISCHARGE_POWER\"] > 0:\n",
    "        return \"covered\"\n",
    "    else:\n",
    "        return \"charged\"\n",
    "    \n",
    "    \n",
    "\n",
    "ds[\"Label\"] = ds.apply(lambda row: label_row(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "charged               52479\n",
       "covered                6936\n",
       "completely covered       27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give me counts of unique values of labels\n",
    "ds[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>charged</th>\n",
       "      <td>52479.0</td>\n",
       "      <td>40.784981</td>\n",
       "      <td>4.822602</td>\n",
       "      <td>7.5</td>\n",
       "      <td>40.50</td>\n",
       "      <td>40.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completely covered</th>\n",
       "      <td>27.0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>3.679465</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covered</th>\n",
       "      <td>6936.0</td>\n",
       "      <td>35.325836</td>\n",
       "      <td>7.244744</td>\n",
       "      <td>9.5</td>\n",
       "      <td>32.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std   min    25%   50%   75%  \\\n",
       "Label                                                                       \n",
       "charged             52479.0  40.784981  4.822602   7.5  40.50  40.5  41.0   \n",
       "completely covered     27.0  38.500000  3.679465  30.0  38.25  40.0  40.5   \n",
       "covered              6936.0  35.325836  7.244744   9.5  32.00  36.0  39.5   \n",
       "\n",
       "                     max  \n",
       "Label                     \n",
       "charged             54.5  \n",
       "completely covered  44.0  \n",
       "covered             54.5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby('Label')['BATTERY_SOC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59442.000000\n",
       "mean        -0.464677\n",
       "std         14.480506\n",
       "min        -53.692001\n",
       "25%         -0.482000\n",
       "50%         -0.351000\n",
       "75%         -0.225000\n",
       "max         72.433006\n",
       "Name: BATTERY_DISCHARGE_POWER, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['BATTERY_DISCHARGE_POWER'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that, we can try to optimize tresholds for SOC so that they help us predict the Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_tensor = torch.tensor(ds['BATTERY_SOC'].values, dtype=torch.float32)\n",
    "external_power_tensor = torch.tensor(ds['GARAGE_EXTERNAL_POWER'].values, dtype=torch.float32)\n",
    "demand_limit_tensor = torch.tensor(ds['DEMAND_LIMIT'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should it work? \n",
    "- the model should predict the \"Label\" (from battery SOC?), and than based on how good the prediction with a curent treshold is update the tresholds\n",
    "- there are 3 tresholds: one for when the battery is covering for all of the grid, one for when the batery is covering some part of the needed energy, pme for whem it is just charging\n",
    "\n",
    "How do I make the treshold be something that gets learned?\n",
    "- predicate 1: learning labels from ds based on battery SOC and tresholds \n",
    "- predicate 2: learning tresholds based on the labels and battery SOC \n",
    "\n",
    "Axioms: \n",
    "- for all x (SOC values): Label IMPLIES x in treshold => if the label is correct than the value is in the treshold   \n",
    "\n",
    "WHAT ACTUALLY SHOULD BE DONE IS TO MAKE A TRESHOLDS PREDICTION NN AND ADD SOME LOGIC RULES THAT SHOULD BE SATISFIED FOR IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1: take the SOC and tresholds and compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(3, 16, 16, 1)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.sigmoid(self.linear_layers[-1](x))\n",
    "        return out\n",
    "    \n",
    "\n",
    "Label = ltn.Predicate(MLP([1, 20, 3]))  # 3 output classes: \"charged\", \"covered\", \"completely covered\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define connectives, quantifiers, and SatAgg\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2: take label and SOC and compute treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_ds = ds[ds[\"Label\"] == \"charged\"]\n",
    "covered_ds = ds[ds[\"Label\"] == \"covered\"]\n",
    "completely_covered_ds = ds[ds[\"Label\"] == \"completely covered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(3, 16, 16, 1)):\n",
    "        super(TMLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.linear_layers[-1](x)\n",
    "        return out\n",
    "    \n",
    "t1 = ltn.Predicate(TMLP([2, 20, 1])) # output is a treshold, input is a battery soc and label \n",
    "\n",
    "# f = ltn.Function(TMLP())\n",
    "# alpha = 0.05\n",
    "tr1 = ltn.Constant(torch.tensor([80]), trainable=True)\n",
    "tr2 = ltn.Constant(torch.tensor([40]), trainable=True)\n",
    "tr3 = ltn.Constant(torch.tensor([15]), trainable=True)\n",
    "\n",
    "# alpha = 0.05\n",
    "# Eq = ltn.Predicate(func=lambda u,v: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(u-v), dim=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "\n",
    "# def compute_sat_level(loader):\n",
    "#     mean_sat = 0\n",
    "#     for x_d, y_d in loader:\n",
    "#         x = ltn.Variable(\"x\", x_d)\n",
    "#         y = ltn.Variable(\"y\", y_d)\n",
    "#         mean_sat += Forall(ltn.diag(x,y), Eq(f(x), y)).value\n",
    "#     mean_sat /= len(loader)\n",
    "#     return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = f.model(data).detach().numpy()\n",
    "        # predictions = np.where(predictions > 0.5, 1., 0.).flatten()\n",
    "        mean_accuracy += torch.nn.MSELoss(labels, predictions)\n",
    "    return mean_accuracy / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(ds[\"Label\"].values)\n",
    "label_tensor = torch.tensor(encoded_labels).float()\n",
    "# label_tensor = torch.tensor(encoded_labels, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Prepare the data\n",
    "soc_tensor = torch.tensor(ds['BATTERY_SOC'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataloader = DataLoader(soc_tensor, label_tensor, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def phi1(features, label):\n",
    "#     print(features)\n",
    "#     print(label)\n",
    "#     label = label.view(-1, 1)\n",
    "#     # soc = features[0].view(-1, 1)\n",
    "#     y = ltn.Variable(\"y\", features)\n",
    "#     s = ltn.Variable(\"s\", label)\n",
    "#     return Forall([y, s], Implies(Label(y), And(Battery_SOC_Greater_tr1(s), t1(y))), p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predicates for each threshold\n",
    "def Battery_SOC_Greater_tr1(tensor):\n",
    "    return tensor >= tr1.value\n",
    "\n",
    "Battery_SOC_Greater_tr1 = ltn.Predicate(None, Battery_SOC_Greater_tr1)\n",
    "\n",
    "def Battery_SOC_Between_tr1_tr2(tensor):\n",
    "    return ((tensor >= tr2.value) & (tensor < tr1.value)).float()\n",
    "\n",
    "\n",
    "Battery_SOC_Between_tr1_tr2 = ltn.Predicate(None, Battery_SOC_Between_tr1_tr2)\n",
    "\n",
    "\n",
    "def Battery_SOC_Less_tr2(tensor):\n",
    "    return (tensor < tr2.value).float()\n",
    "\n",
    "Battery_SOC_Less_tr2 = ltn.Predicate(None, Battery_SOC_Less_tr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_label(tensor):\n",
    "    if Battery_SOC_Greater_tr1(tensor):\n",
    "        return 'completely covered'\n",
    "    elif Battery_SOC_Between_tr1_tr2(tensor):\n",
    "        return 'covered'\n",
    "    else:\n",
    "        return 'charged'\n",
    "\n",
    "map_to_label = ltn.Function(None, map_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placPred(tensor):\n",
    "    return tensor\n",
    "\n",
    "placPred = ltn.Predicate(None, placPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problems seems to be with how I do the predicates => they seem to need a model parameter if trainable!!!!\n",
    "- for each treshold we should have a NN that predicts it's value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(tr1.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "# Exists(d,\n",
    "#       Forall([x, y],\n",
    "#             Eq(x, y),\n",
    "#             cond_vars=[x, y, d],\n",
    "#             cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "#             )).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4037785427755124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m     i2 \u001b[38;5;241m=\u001b[39m (\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m     i1 \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m     i0 \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(Label.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        i2 = (labels == 2)\n",
    "        i1 = (labels == 1)\n",
    "        i0 = (labels == 0)\n",
    "\n",
    "        l2 = ltn.Variable(\"l2\", labels[i2] / 2)\n",
    "        l1 = ltn.Variable(\"l1\", labels[i1] / 2)\n",
    "        l0 = ltn.Variable(\"l0\", labels[i0] / 2)\n",
    "        p2 = ltn.Variable(\"p2\", data[i2])\n",
    "        p1 = ltn.Variable(\"p1\", data[i1])\n",
    "        p0 = ltn.Variable(\"p0\", data[i0])\n",
    "    \n",
    "        sat_agg = SatAgg(\n",
    "            Forall(p2, Implies(Battery_SOC_Greater_tr1(p2), placPred(l2)), p=5).value.mean(),\n",
    "            Forall(p1, Implies(Battery_SOC_Between_tr1_tr2(p1), placPred(l1)), p=5).value.mean(),\n",
    "            Forall(p0, Implies(Battery_SOC_Less_tr2(p0), placPred(l0)), p=5).value.mean()\n",
    "        )\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = 1 - sat_agg\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate the loss and update the weights\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {train_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "# Exists(d,\n",
    "#       Forall([x, y],\n",
    "#             Eq(x, y),\n",
    "#             cond_vars=[x, y, d],\n",
    "#             cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "#             )).value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As showed in the example, in order to use a guarded quantification it is enough to specify some condition variables (`cond_vars` parameter) and a\n",
    "condition function (`cond_fn` parameter). In particular, `cond_vars` requires a list of LTN variables, while\n",
    "`cond_fn` requires a function. The function computes a boolean mask, then the mask is used to select the values on which\n",
    "the aggregation has to be computed.\n",
    "\n",
    "In this specific example, the guarded quantification is used for aggregating over pairs of points whose distance is under a certain\n",
    "threshold, specified by variable $d$. All the other pairs of points are not considered during the aggregation.\n",
    "\n",
    "The guarded option is particularly useful to propagate gradients (see notebook on learning) only over a subset of the\n",
    "domains, namely the domains which verifies the condition $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's restart and do the approach diferently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a model that predicts the labels, than from this we will add trainable constants for tresholds \n",
    "Label\n",
    "- charged               52485\n",
    "- covered                6929\n",
    "- completely covered       28\n",
    "\n",
    "For this specific task, LTN uses the following language and grounding:\n",
    "\n",
    "**Domains:**\n",
    "- $feat$, denoting the examples;\n",
    "- $labels$, denoting the class labels.\n",
    "\n",
    "**Variables:**\n",
    "- $x_A, x_B, x_C$ for the examples of classes $A$, $B$, and $C$;\n",
    "- $x$ for all examples;\n",
    "- $D(x_A) = D(x_B) = D(x_C) = D(x) = items$.\n",
    "\n",
    "**Constants:**\n",
    "- $l_A, l_B, l_C$, the labels of classes $A$ (charged), $B$ (covered), $C$ (completely covered), respectively;\n",
    "- $D(l_A) = D(l_B) = D(l_C) = labels$.\n",
    "\n",
    "**Predicates:**\n",
    "- $P(x,l)$ denoting the fact that item $x$ is classified as $l$;\n",
    "- $D_{in}(P) = items, labels$.\n",
    "\n",
    "**Axioms:**\n",
    "\n",
    "- $\\forall x_A P(x_A, l_A)$: all the examples of class $A$ should have label $l_A$;\n",
    "- $\\forall x_B P(x_B, l_B)$: all the examples of class $B$ should have label $l_B$;\n",
    "- $\\forall x_C P(x_C, l_C)$: all the examples of class $C$ should have label $l_C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ds[['WALLBOX_FASTCHARGER_POWER', 'BATTERY_SOC']]\n",
    "target = ds['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALLBOX_FASTCHARGER_POWER</th>\n",
       "      <th>BATTERY_SOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59442.000000</td>\n",
       "      <td>59442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.665066</td>\n",
       "      <td>40.146942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.522631</td>\n",
       "      <td>5.453018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.150472</td>\n",
       "      <td>40.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.159256</td>\n",
       "      <td>40.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.169050</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.319511</td>\n",
       "      <td>54.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WALLBOX_FASTCHARGER_POWER   BATTERY_SOC\n",
       "count               59442.000000  59442.000000\n",
       "mean                    9.665066     40.146942\n",
       "std                    22.522631      5.453018\n",
       "min                     0.009000      7.500000\n",
       "25%                     0.150472     40.500000\n",
       "50%                     0.159256     40.500000\n",
       "75%                     0.169050     41.000000\n",
       "max                    80.319511     54.500000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SOC values when the battery is being charged\n",
    "soc_charging = ds[ds['BATTERY_SOC'] < 9]['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "charged    1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[(ds['BATTERY_SOC'] >= 0) & (ds['BATTERY_SOC'] <= 8)]['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14779    charged\n",
      "14780    charged\n",
      "14781    charged\n",
      "14782    charged\n",
      "14783    charged\n",
      "          ...   \n",
      "34340    charged\n",
      "34341    charged\n",
      "34342    charged\n",
      "34343    charged\n",
      "34344    charged\n",
      "Name: Label, Length: 72, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(soc_charging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we define the constants\n",
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))\n",
    "\n",
    "# we define predicate P\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, layer_sizes=(2, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n",
    "\n",
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "\n",
    "# we define the connectives, quantifiers, and the SatAgg\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Create a list of indices for each class\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        # Calculate the number of samples per class in each batch\n",
    "        samples_per_class = max(1, self.batch_size // len(self.unique_labels))\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                # Randomly sample indices for this class\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "            # If the batch size is not a multiple of the number of classes, fill the rest of the batch randomly\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]\n",
    "\n",
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "# it computes the overall accuracy of the predictions of the trained model using the given data loader\n",
    "# (train or test)\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test loader features_train, features_test, target_train, target_test\n",
    "train_loader = DataLoader(features_train, target_train, 256, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the thresholds from 0 to 100\n",
    "SOC_val = ltn.Variable(\"SOC_val\", torch.tensor([i for i in range(101)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "# Exists(tr1,\n",
    "#       Forall([x, y],\n",
    "#             Eq(x, y),\n",
    "#             cond_vars=[x, y, d],\n",
    "#             cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "#             )).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Battery_SOC_smaller(tensor, tr):\n",
    "    return tensor <= tr\n",
    "\n",
    "Battery_SOC_smaller = ltn.Predicate(None, Battery_SOC_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_corect(tensor):\n",
    "#     return tensor > tr\n",
    "\n",
    "# Battery_SOC_smaller = ltn.Predicate(None, Battery_SOC_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns a single value (threshold) given a set of features. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ThresholdModel, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :return: threshold for example x\n",
    "        \"\"\"\n",
    "        x = self.elu(self.linear1(x))\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "    \n",
    "# we define function f\n",
    "model = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr1 = ltn.Constant(torch.tensor([80]), trainable=True)\n",
    "# tr2 = ltn.Constant(torch.tensor([40]), trainable=True)\n",
    "# tr3 = ltn.Constant(torch.tensor([15.0]), trainable=True)\n",
    "# tr3 = ltn.Variable(\"tr3\", tr3.value)\n",
    "\n",
    "tresholds = [ltn.Constant(torch.tensor([i]), trainable=True) for i in range(1)]\n",
    "# tr1v = ltn.Variable(\"tr1\", tr1.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treshold might be maybe found like this: exists a treshold such that for all X in A the labels are only A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4309 | Train Sat 0.555 | Test Sat 0.558 | Train Acc 0.663 | Test Acc 0.663\n",
      "Lower treshold: tensor(12.8166)\n",
      " epoch 30 | loss 0.4097 | Train Sat 0.564 | Test Sat 0.572 | Train Acc 0.665 | Test Acc 0.664\n",
      "Lower treshold: tensor(13.2297)\n",
      " epoch 60 | loss 0.4086 | Train Sat 0.567 | Test Sat 0.574 | Train Acc 0.665 | Test Acc 0.667\n",
      "Lower treshold: tensor(12.7596)\n",
      " epoch 90 | loss 0.3946 | Train Sat 0.621 | Test Sat 0.604 | Train Acc 0.683 | Test Acc 0.683\n",
      "Lower treshold: tensor(13.0641)\n",
      " epoch 120 | loss 0.4031 | Train Sat 0.603 | Test Sat 0.594 | Train Acc 0.665 | Test Acc 0.664\n",
      "Lower treshold: tensor(12.7330)\n",
      " epoch 150 | loss 0.3908 | Train Sat 0.625 | Test Sat 0.605 | Train Acc 0.666 | Test Acc 0.667\n",
      "Lower treshold: tensor(12.9747)\n",
      " epoch 180 | loss 0.3957 | Train Sat 0.600 | Test Sat 0.591 | Train Acc 0.665 | Test Acc 0.666\n",
      "Lower treshold: tensor(12.6848)\n",
      " epoch 210 | loss 0.4075 | Train Sat 0.576 | Test Sat 0.580 | Train Acc 0.665 | Test Acc 0.666\n",
      "Lower treshold: tensor(12.6559)\n",
      " epoch 240 | loss 0.3917 | Train Sat 0.628 | Test Sat 0.600 | Train Acc 0.666 | Test Acc 0.665\n",
      "Lower treshold: tensor(13.3532)\n",
      " epoch 270 | loss 0.3944 | Train Sat 0.641 | Test Sat 0.591 | Train Acc 0.667 | Test Acc 0.667\n",
      "Lower treshold: tensor(12.8243)\n",
      " epoch 300 | loss 0.4071 | Train Sat 0.584 | Test Sat 0.592 | Train Acc 0.687 | Test Acc 0.686\n",
      "Lower treshold: tensor(12.6873)\n",
      " epoch 330 | loss 0.4034 | Train Sat 0.606 | Test Sat 0.599 | Train Acc 0.669 | Test Acc 0.669\n",
      "Lower treshold: tensor(13.0109)\n",
      " epoch 360 | loss 0.3967 | Train Sat 0.635 | Test Sat 0.601 | Train Acc 0.669 | Test Acc 0.669\n",
      "Lower treshold: tensor(12.9897)\n",
      " epoch 390 | loss 0.3892 | Train Sat 0.598 | Test Sat 0.567 | Train Acc 0.668 | Test Acc 0.669\n",
      "Lower treshold: tensor(12.8642)\n",
      " epoch 420 | loss 0.3895 | Train Sat 0.625 | Test Sat 0.557 | Train Acc 0.671 | Test Acc 0.674\n",
      "Lower treshold: tensor(13.3686)\n",
      " epoch 450 | loss 0.3881 | Train Sat 0.567 | Test Sat 0.549 | Train Acc 0.667 | Test Acc 0.667\n",
      "Lower treshold: tensor(12.8700)\n",
      " epoch 480 | loss 0.4046 | Train Sat 0.585 | Test Sat 0.560 | Train Acc 0.666 | Test Acc 0.667\n",
      "Lower treshold: tensor(12.8662)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(list(P.parameters()) + list(model.parameters()) + [i.value for i in tresholds], lr=0.001)\n",
    "# optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        # tr = ltn.Variable(\"tr\", torch.stack([i.value for i in tresholds]))\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 1]) # class A examples\n",
    "        # x_B_SOC = ltn.Variable(\"x_B_SOC\", data[labels == 1][:, 1]) # class A examples\n",
    "        # x_C_SOC = ltn.Variable(\"x_C_SOC\", data[labels == 2][:, 1]) # class A examples\n",
    "\n",
    "        tresh1 = model(x_A_SOC)\n",
    "        tr = ltn.Variable(\"tr1\", tresh1.value)\n",
    "        # tresh2 = model(x_B_SOC)\n",
    "        # tr2 = ltn.Variable(\"tr2\", tresh2.value)\n",
    "        # tresh3 = model(x_C_SOC)\n",
    "        # tr3 = ltn.Variable(\"tr3\", tresh3.value)\n",
    "        # print(Exists(tr, Forall(x_A, Implies(P(x_A, l_A, training=True), Battery_SOC_smaller(x_A_SOC, tr)))))\n",
    "        # print(Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tr)).value.mean())\n",
    "        actual_tresh1_value = tresh1.value.detach().clone()  # Store the actual value before applying sigmoid\n",
    "        tr = ltn.Variable(\"tr1\", torch.sigmoid(tresh1.value))\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True)),\n",
    "            # Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tr)).value.mean(),\n",
    "            Exists(tr, Forall(x_A, Implies(P(x_A, l_A, training=True), Battery_SOC_smaller(x_A_SOC, tr)))).value.mean(),\n",
    "            # Exists(tr2, Forall(x_B_SOC, Battery_SOC_smaller(x_B_SOC, tr2), p=5)),\n",
    "            # Exists(tr3, Forall(x_C_SOC, Battery_SOC_smaller(x_C_SOC, tr3), p=5))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 30 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "        # print(tr1.value.mean(), tr2.value.mean(), tr3.value.mean())\n",
    "        print(\"Lower treshold:\", actual_tresh1_value.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
