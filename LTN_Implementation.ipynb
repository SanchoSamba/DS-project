{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains combination combination of our work on the LTN. It consinsts of the most important findings and LTN implementation in a structured way. This is not all the code that was developed during the project and only the most interesting parts. More code is available on the development branch in few separate notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of libraries and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ltn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataset with no labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_time', 'GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
       "       'DEMAND_LIMIT_INDICATOR', 'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
       "       'BATTERY_CHARGED_ENERGY', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
       "       'PV_ENERGY', 'WALLBOX_ALPHA_ENERGY', 'WALLBOX_ALPHA_POWER',\n",
       "       'WALLBOX_1_ENERGY', 'WALLBOX_1_POWER', 'WALLBOX_2_ENERGY',\n",
       "       'WALLBOX_2_POWER', 'WALLBOX_3_ENERGY', 'WALLBOX_3_POWER',\n",
       "       'WALLBOX_A_ENERGY', 'WALLBOX_A_POWER', 'WALLBOX_B_ENERGY',\n",
       "       'WALLBOX_B_POWER', 'WALLBOX_C_ENERGY', 'WALLBOX_C_POWER',\n",
       "       'WALLBOX_FASTCHARGER_ENERGY', 'WALLBOX_FASTCHARGER_POWER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_l.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_l[['GARAGE_EXTERNAL_POWER','DEMAND_LIMIT',\n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'WALLBOX_FASTCHARGER_POWER', 'PV_POWER'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset that is independent form GT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth labeling (whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ds = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    # elif row[\"BATTERY_SOC\"] < 15:\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the labeling function to create the new column \"DRAWN_FROM\"\n",
    "gt_ds[\"DRAWN_FROM\"] = gt_ds.apply(label_charging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRAWN_FROM\n",
       "Battery Charged from Grid                          54783\n",
       "Partially Covered by Local Battery                  4457\n",
       "Battery Discharge Stopped due to Battery Health      202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_ds['DRAWN_FROM'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small labeled dataset (only the part that follows GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.5 # Tolerance for the power limit\n",
    "SOC_less_15 = gt_ds[(gt_ds[\"BATTERY_SOC\"]<=15) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]<=0)]\n",
    "SOC_less_40_1 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>15) &(gt_ds[\"BATTERY_SOC\"]<40) & (gt_ds[\"GARAGE_EXTERNAL_POWER\"]<50) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]<0)]\n",
    "SOC_less_40_2 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>15) &(gt_ds[\"BATTERY_SOC\"]<40) & (gt_ds[\"GARAGE_EXTERNAL_POWER\"]<=(50+delta)) & ((50-delta)<=gt_ds[\"GARAGE_EXTERNAL_POWER\"]) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]>=0)]\n",
    "SOC_more_40 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>=40) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]>=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset, that is kept: 16.313381110998957%\n"
     ]
    }
   ],
   "source": [
    "gt_ds_small = pd.concat([SOC_less_15, SOC_less_40_1, SOC_less_40_2, SOC_more_40], ignore_index=True)\n",
    "gt_ds_small = gt_ds_small.drop_duplicates()\n",
    "print(f\"Percentage of dataset, that is kept: {len(gt_ds_small)/len(gt_ds)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncoment and use for testing Model 1 - small dataset\n",
    "features = gt_ds_small.drop(['DEMAND_LIMIT','GARAGE_EXTERNAL_POWER', 'DRAWN_FROM'], axis=1)\n",
    "target = gt_ds_small['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = gt_ds.drop(['DEMAND_LIMIT','GARAGE_EXTERNAL_POWER', 'DRAWN_FROM'], axis=1)\n",
    "target = gt_ds['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: \"Battery Charged from Grid\" is encoded as 0\n",
      "Original Class: \"Battery Discharge Stopped due to Battery Health\" is encoded as 1\n",
      "Original Class: \"Partially Covered by Local Battery\" is encoded as 2\n"
     ]
    }
   ],
   "source": [
    "# Print classes and their labels\n",
    "for label, original_class in enumerate(encoder.classes_):\n",
    "    print(f'Original Class: \"{original_class}\" is encoded as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Tensor Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LTN classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test, encode the labels into ltn Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)\n",
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models implementation and main predicate\n",
    "\n",
    "We need two separated models because we need both logits and probabilities. Logits are used to compute the classification accuracy, while probabilities are interpreted as truth values to compute the satisfaction level of the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(4, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        samples_per_class = self.batch_size // len(self.unique_labels)\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use LTN to define a predicate that will make use of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities used by LTN, logistic operations, satisfaction and accuracy retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(features_train, target_train, 64, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.2683 | Train Sat 0.770 | Test Sat 0.771 | Train Acc 0.928 | Test Acc 0.929\n",
      " epoch 20 | loss 0.2072 | Train Sat 0.792 | Test Sat 0.782 | Train Acc 0.943 | Test Acc 0.941\n",
      " epoch 40 | loss 0.2096 | Train Sat 0.793 | Test Sat 0.801 | Train Acc 0.944 | Test Acc 0.943\n",
      " epoch 60 | loss 0.2055 | Train Sat 0.799 | Test Sat 0.798 | Train Acc 0.943 | Test Acc 0.944\n",
      " epoch 80 | loss 0.2040 | Train Sat 0.795 | Test Sat 0.785 | Train Acc 0.944 | Test Acc 0.941\n",
      " epoch 100 | loss 0.2022 | Train Sat 0.802 | Test Sat 0.809 | Train Acc 0.949 | Test Acc 0.949\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) \n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) \n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) \n",
    "\n",
    "        # calculating the satisfaction level of the knowledge base, used in guided learning\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    # Here is an example of simple quering of the logistic formulas\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 119 | loss 0.2018 | Train Sat 0.801 | Test Sat 0.808 | Train Acc 0.948 | Test Acc 0.950\n"
     ]
    }
   ],
   "source": [
    "print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "\n",
    "# epoch 119 | loss 0.2018 | Train Sat 0.801 | Test Sat 0.808 | Train Acc 0.948 | Test Acc 0.950"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that model already after 20 epochs we can see Test Acc == 0.941 and the rule satisfaction on Test == 0.782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules satisfaction presentation\n",
    "Rules satisfaction allows for a simple verification of some believes, theories as to the data (or simply verification of what we thing could be a ,,rule'' as to the system behaviour). This, to some extend, is usually possible with data analysis (in case of simple rules), but as shown later on - plays a crucial role in finding a treshold and allows for a things outside of the scope of the simple data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = DataLoader(torch.tensor(features.to_numpy()).float(), torch.tensor(en_targ), 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the satisfaction level of the rule from the GT \n",
    "- If SOC < 15 than Battery Discharge Stopped due to Battery Health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discharge_stopped(tensor):\n",
    "    return tensor <= 0\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 15 \n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "discharge_stopped = ltn.Predicate(None, discharge_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phi(features, label):\n",
    "    sc = features[0].view(-1,1)\n",
    "    bp = features[1].view(-1,1)\n",
    "\n",
    "    bp = ltn.Variable(\"bp\", bp)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall(s, Implies(Battery_SOC_small(s), discharge_stopped(bp)), p=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7488)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(testing_set, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold optimization (3 Models mentioned in the report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a simple regression model, that will be used for finding the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns a single value (threshold) given a set of features. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ThresholdModel, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :return: threshold for example x\n",
    "        \"\"\"\n",
    "        x = self.elu(self.linear1(x))\n",
    "        out = self.linear2(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))\n",
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple query to present checking rule satisfaction during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Battery_SOC_smaller(tensor, tr):\n",
    "    return tensor <= tr\n",
    "\n",
    "Battery_SOC_smaller = ltn.Predicate(None, Battery_SOC_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicates used to guide the regression task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.sigmoid(tensor - tr))\n",
    "Battery_SOC_larger2 = ltn.Predicate(func=lambda tensor, tr: torch.sigmoid(tr - tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 and Model 2 \n",
    "- to run it corectly make sure to use the right dataset\n",
    "- for Model 1 we run it on small dataset - that results in a value close to 15 for 1st threshold and close to 40 for the second one (If we comment parts of code that are used for threshold2 in sat_agg part, than the value will be closer to 15% SOC, that happens since probably the overall loss is smaller and our rules are not optimal, or lack some extra information)\n",
    "- for Model 2 make sure to run it on the big dataset. Resulting thresholds should be: for 1st the threshold is much closer to 15 than for small dataset, for 2nd the value is around 44% SOC, which is in agreement with our findings from the DNN model\n",
    "\n",
    "Generally the models work by combining the classification task and regression task together - we optimize both at the same time. The models aim to optimize rules specified in sat_agg. The classification model is present, because we do want to include our knowledge from GT model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.5540 | Train Sat 0.766 | Test Sat 0.768 | Train Acc 0.928 | Test Acc 0.934\n",
      "Lower treshold 1: tensor(8.5343, grad_fn=<MeanBackward0>) tensor(0.1256)\n",
      "Lower treshold 2: tensor(18.5811, grad_fn=<MeanBackward0>) tensor(0.)\n",
      " epoch 20 | loss 0.3829 | Train Sat 0.797 | Test Sat 0.791 | Train Acc 0.942 | Test Acc 0.946\n",
      "Lower treshold 1: tensor(14.8571, grad_fn=<MeanBackward0>) tensor(0.7316)\n",
      "Lower treshold 2: tensor(44.0128, grad_fn=<MeanBackward0>) tensor(0.7618)\n",
      " epoch 40 | loss 0.3829 | Train Sat 0.800 | Test Sat 0.797 | Train Acc 0.944 | Test Acc 0.943\n",
      "Lower treshold 1: tensor(14.9607, grad_fn=<MeanBackward0>) tensor(0.9057)\n",
      "Lower treshold 2: tensor(44.3005, grad_fn=<MeanBackward0>) tensor(0.7256)\n",
      " epoch 60 | loss 0.3849 | Train Sat 0.799 | Test Sat 0.803 | Train Acc 0.946 | Test Acc 0.945\n",
      "Lower treshold 1: tensor(15.4450, grad_fn=<MeanBackward0>) tensor(0.8292)\n",
      "Lower treshold 2: tensor(44.5021, grad_fn=<MeanBackward0>) tensor(0.5837)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 28\u001b[0m\n\u001b[0;32m     21\u001b[0m tresh \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtre1\u001b[39m\u001b[38;5;124m\"\u001b[39m, tresh1\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m     22\u001b[0m tresh2 \u001b[38;5;241m=\u001b[39m ltn\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtre2\u001b[39m\u001b[38;5;124m\"\u001b[39m, tresh2\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m     24\u001b[0m sat_agg \u001b[38;5;241m=\u001b[39m SatAgg(    \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# there is a treshold such that SOC is smaller than treshold \u001b[39;00m\n\u001b[0;32m     26\u001b[0m     Forall(x_A, P(x_A, l_A, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[0;32m     27\u001b[0m     Forall(x_B, P(x_B, l_B, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[1;32m---> 28\u001b[0m     Forall(x_C, \u001b[43mP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m),\n\u001b[0;32m     29\u001b[0m     Exists(tresh, Forall(x_B_SOC, Battery_SOC_larger2(x_B_SOC, tresh), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m     30\u001b[0m     Exists(tresh, Forall(x_C_SOC, Battery_SOC_smaller2(x_C_SOC, tresh), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) ,p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m     31\u001b[0m     Exists(tresh2, Forall(x_A_SOC, Battery_SOC_larger2(x_A_SOC, tresh2), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) ,p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m     32\u001b[0m     Exists(tresh2, Forall(x_C_SOC, Battery_SOC_smaller2(x_C_SOC, tresh2), p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) ,p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m sat_agg\n\u001b[0;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\ltn\\core.py:613\u001b[0m, in \u001b[0;36mPredicate.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m proc_objs, output_vars, output_shape \u001b[38;5;241m=\u001b[39m process_ltn_objects(inputs)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# the management of the input is left to the model or the lambda function\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproc_objs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# check if output of predicate contains only truth values, namely values in the range [0., 1.]\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mlogical_and(output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, output \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m), \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 33\u001b[0m, in \u001b[0;36mLogitsToPredicate.forward\u001b[1;34m(self, x, l, training)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, l, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 33\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[0;32m     35\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(probs \u001b[38;5;241m*\u001b[39m l, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 13\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(layer(x))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m---> 13\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adamr\\anaconda3\\envs\\LTN\\lib\\site-packages\\torch\\nn\\functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(list(P.parameters()) + list(tmodel.parameters()), lr=0.001)\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 0])\n",
    "        x_B_SOC = ltn.Variable(\"x_B_SOC\", data[labels == 1][:, 0])\n",
    "        x_C_SOC = ltn.Variable(\"x_C_SOC\", data[labels == 2][:, 0])\n",
    "\n",
    "        tr_soc = ltn.Variable(\"tr_soc\", torch.from_numpy(np.concatenate([data[labels == 0][:, 0], data[labels == 1][:, 0]])))\n",
    "        tr2_soc = ltn.Variable(\"tr_soc\", torch.from_numpy(np.concatenate([data[labels == 0][:, 0], data[labels == 2][:, 0]])))\n",
    "        tresh1 = tmodel(x_B_SOC)\n",
    "        tresh2 = tmodel(x_A_SOC)\n",
    "        \n",
    "        tresh = ltn.Variable(\"tre1\", tresh1.value)\n",
    "        tresh2 = ltn.Variable(\"tre2\", tresh2.value)\n",
    "        \n",
    "        sat_agg = SatAgg(    \n",
    "            # there is a treshold such that SOC is smaller than treshold \n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True)),\n",
    "            Exists(tresh, Forall(x_B_SOC, Battery_SOC_larger2(x_B_SOC, tresh), p=5), p=5),\n",
    "            Exists(tresh, Forall(x_C_SOC, Battery_SOC_smaller2(x_C_SOC, tresh), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_A_SOC, Battery_SOC_larger2(x_A_SOC, tresh2), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_C_SOC, Battery_SOC_smaller2(x_C_SOC, tresh2), p=5) ,p=5),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean(), Forall(x_B_SOC, Battery_SOC_smaller(x_B_SOC, tresh)).value.mean())\n",
    "        print(\"Lower treshold 2:\", tresh2.value.mean(), Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh2)).value.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  epoch 0 | loss 0.5941 | Train Sat 0.664 | Test Sat 0.671 | Train Acc 0.841 | Test Acc 0.844\n",
    "# Lower treshold 1: tensor(5.6715, grad_fn=<MeanBackward0>) tensor(0.)\n",
    "# Lower treshold 2: tensor(18.6631, grad_fn=<MeanBackward0>) tensor(0.)\n",
    "#  epoch 20 | loss 0.3606 | Train Sat 0.684 | Test Sat 0.678 | Train Acc 0.845 | Test Acc 0.850\n",
    "# Lower treshold 1: tensor(13.8472, grad_fn=<MeanBackward0>) tensor(0.7308)\n",
    "# Lower treshold 2: tensor(39.3693, grad_fn=<MeanBackward0>) tensor(0.7790)\n",
    "#  epoch 40 | loss 0.3577 | Train Sat 0.686 | Test Sat 0.679 | Train Acc 0.850 | Test Acc 0.860\n",
    "# Lower treshold 1: tensor(14.0685, grad_fn=<MeanBackward0>) tensor(0.7352)\n",
    "# Lower treshold 2: tensor(39.5058, grad_fn=<MeanBackward0>) tensor(0.7332)\n",
    "#  epoch 60 | loss 0.3599 | Train Sat 0.687 | Test Sat 0.679 | Train Acc 0.851 | Test Acc 0.840\n",
    "# Lower treshold 1: tensor(13.8678, grad_fn=<MeanBackward0>) tensor(0.6503)\n",
    "# Lower treshold 2: tensor(38.7538, grad_fn=<MeanBackward0>) tensor(0.5950)\n",
    "#  epoch 80 | loss 0.3525 | Train Sat 0.685 | Test Sat 0.687 | Train Acc 0.849 | Test Acc 0.859\n",
    "# Lower treshold 1: tensor(14.5301, grad_fn=<MeanBackward0>) tensor(0.7022)\n",
    "# Lower treshold 2: tensor(39.4339, grad_fn=<MeanBackward0>) tensor(0.7049)\n",
    "#  epoch 100 | loss 0.3597 | Train Sat 0.678 | Test Sat 0.685 | Train Acc 0.851 | Test Acc 0.854\n",
    "# Lower treshold 1: tensor(13.4160, grad_fn=<MeanBackward0>) tensor(0.7180)\n",
    "# Lower treshold 2: tensor(42.0435, grad_fn=<MeanBackward0>) tensor(0.5395)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the big GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 0 | loss 0.5540 | Train Sat 0.766 | Test Sat 0.768 | Train Acc 0.928 | Test Acc 0.934\n",
    "# Lower treshold 1: tensor(8.5343, grad_fn=<MeanBackward0>) tensor(0.1256)\n",
    "# Lower treshold 2: tensor(18.5811, grad_fn=<MeanBackward0>) tensor(0.)\n",
    "#  epoch 20 | loss 0.3829 | Train Sat 0.797 | Test Sat 0.791 | Train Acc 0.942 | Test Acc 0.946\n",
    "# Lower treshold 1: tensor(14.8571, grad_fn=<MeanBackward0>) tensor(0.7316)\n",
    "# Lower treshold 2: tensor(44.0128, grad_fn=<MeanBackward0>) tensor(0.7618)\n",
    "#  epoch 40 | loss 0.3829 | Train Sat 0.800 | Test Sat 0.797 | Train Acc 0.944 | Test Acc 0.943\n",
    "# Lower treshold 1: tensor(14.9607, grad_fn=<MeanBackward0>) tensor(0.9057)\n",
    "# Lower treshold 2: tensor(44.3005, grad_fn=<MeanBackward0>) tensor(0.7256)\n",
    "#  epoch 60 | loss 0.3849 | Train Sat 0.799 | Test Sat 0.803 | Train Acc 0.946 | Test Acc 0.945\n",
    "# Lower treshold 1: tensor(15.4450, grad_fn=<MeanBackward0>) tensor(0.8292)\n",
    "# Lower treshold 2: tensor(44.5021, grad_fn=<MeanBackward0>) tensor(0.5837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 \n",
    "In this task we only use the Regression model to find the best thresholds. Thanks to it we retrvie the 44% SOC. Well-defined rules enable us to find thresholds independently of GT. This leads to the conclusion that it is possible to discover other system rules by simply defining expert knowledge as a set of constraints that guide the regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part creates the DS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tmp\\ipykernel_25548\\3397578051.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_data[\"DRAWN_FROM\"] = s_data.apply(label_charging, axis=1)\n"
     ]
    }
   ],
   "source": [
    "s_data = ds_l[['_time','GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
    "      #  'DEMAND_LIMIT_INDICATOR', \n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'BATTERY_CHARGED_ENERGY','WALLBOX_FASTCHARGER_POWER', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
    "       'PV_ENERGY'\n",
    "    ]]\n",
    "\n",
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    # elif row[\"BATTERY_SOC\"] < 15:\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "s_data[\"DRAWN_FROM\"] = s_data.apply(label_charging, axis=1)\n",
    "\n",
    "\n",
    "features = s_data.drop(['_time','DEMAND_LIMIT', 'PV_POWER','PV_ENERGY', 'DRAWN_FROM'], axis=1)\n",
    "target = s_data['DRAWN_FROM']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: \"Battery Charged from Grid\" is encoded as 0\n",
      "Original Class: \"Battery Discharge Stopped due to Battery Health\" is encoded as 1\n",
      "Original Class: \"Partially Covered by Local Battery\" is encoded as 2\n"
     ]
    }
   ],
   "source": [
    "# Print classes and their labels\n",
    "for label, original_class in enumerate(encoder.classes_):\n",
    "    print(f'Original Class: \"{original_class}\" is encoded as {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)\n",
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()\n",
    "\n",
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you run DataLoader from the 1st part of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(features_train, target_train, 64, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BDP_neg(tensor):\n",
    "    return tensor <= 0\n",
    "\n",
    "BDP_neg = ltn.Predicate(None, BDP_neg)\n",
    "\n",
    "def BDP_p(tensor):\n",
    "    return tensor >= 0\n",
    "\n",
    "BDP_p = ltn.Predicate(None, BDP_p)\n",
    "\n",
    "def gep_under(tensor):\n",
    "    return tensor < 50\n",
    "\n",
    "gep_under = ltn.Predicate(None, gep_under)\n",
    "def gep_abov(tensor):\n",
    "    return tensor >= 50\n",
    "\n",
    "gep_abov = ltn.Predicate(None, gep_abov)\n",
    "\n",
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.sigmoid(tensor - tr))\n",
    "Battery_SOC_larger2 = ltn.Predicate(func=lambda tensor, tr: torch.sigmoid(tr - tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(tmodel.parameters()), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        x = ltn.Variable(\"x\", data)\n",
    "        gep = ltn.Variable(\"gep\", data[:, 0])\n",
    "        soc = ltn.Variable(\"soc\", data[:, 1])\n",
    "        bce = ltn.Variable(\"bce\", data[:, 3])\n",
    "        bde = ltn.Variable(\"bde\", data[:, 5])\n",
    "\n",
    "        x_B_SOC = ltn.Variable(\"x_B_SOC\", data[labels == 1][:, 0])\n",
    "\n",
    "        x_C_SOC = ltn.Variable(\"x_C_SOC\", data[labels == 2][:, 0])\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 0])\n",
    "\n",
    "        tresh1 = tmodel(soc)\n",
    "        tresh2 = tmodel(soc)\n",
    "        tresh = ltn.Variable(\"tre1\", tresh1.value)\n",
    "        tresh2 = ltn.Variable(\"tre2\", tresh2.value)\n",
    "        # print(Exists(tresh, Forall(soc, And(BDP_neg(bdp), Battery_SOC_smaller2(soc, tresh)), p=5), p=5))\n",
    "        sat_agg = SatAgg(    \n",
    "            Exists(tresh, Forall(soc, Implies(And(gep_under(gep), BDP_p(bde)), Battery_SOC_larger2(soc, tresh)), p=5), p=5).value.mean(),\n",
    "            Exists(tresh, Forall(soc, Implies(And(gep_under(gep), BDP_p(bce)), Battery_SOC_smaller2(soc, tresh)), p=5), p=5).value.mean(),\n",
    "            Exists(tresh2, Forall(soc, Implies(And(gep_under(gep), BDP_p(bde)), Battery_SOC_larger2(soc, tresh2)), p=5), p=5).value.mean(),\n",
    "            Exists(tresh2, Forall(soc, Implies(And(gep_abov(gep), BDP_p(bce)), Battery_SOC_smaller2(soc, tresh2)), p=5), p=5).value.mean(),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 1 == 0:\n",
    "        print(\" epoch %d | loss %.4f\"\n",
    "              %(epoch, train_loss))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean(), Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh)).value.mean())\n",
    "        print(\"Lower treshold 2:\", tresh2.value.mean(), Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh2)).value.mean())\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
