{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains combination combination of our work on the LTN. It consinsts of the most important findings and LTN implementation in a structured way. This is not all the code that was developed during the project and only the most interesting parts. More code is available on the development branch in few separate notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of libraries and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ltn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l = pd.read_csv('src\\data\\Stud_E-mobility_data_staticLimit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main dataset with no labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_time', 'GARAGE_EXTERNAL_POWER', 'DEMAND_LIMIT',\n",
       "       'DEMAND_LIMIT_INDICATOR', 'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
       "       'BATTERY_CHARGED_ENERGY', 'BATTERY_DISCHARGED_ENERGY', 'PV_POWER',\n",
       "       'PV_ENERGY', 'WALLBOX_ALPHA_ENERGY', 'WALLBOX_ALPHA_POWER',\n",
       "       'WALLBOX_1_ENERGY', 'WALLBOX_1_POWER', 'WALLBOX_2_ENERGY',\n",
       "       'WALLBOX_2_POWER', 'WALLBOX_3_ENERGY', 'WALLBOX_3_POWER',\n",
       "       'WALLBOX_A_ENERGY', 'WALLBOX_A_POWER', 'WALLBOX_B_ENERGY',\n",
       "       'WALLBOX_B_POWER', 'WALLBOX_C_ENERGY', 'WALLBOX_C_POWER',\n",
       "       'WALLBOX_FASTCHARGER_ENERGY', 'WALLBOX_FASTCHARGER_POWER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_l.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_l[['GARAGE_EXTERNAL_POWER','DEMAND_LIMIT',\n",
    "       'BATTERY_SOC', 'BATTERY_DISCHARGE_POWER',\n",
    "       'WALLBOX_FASTCHARGER_POWER', 'PV_POWER'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth labeling (whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ds = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_charging(row):\n",
    "    if row[\"BATTERY_SOC\"] > 80:\n",
    "        return \"Fully Covered by Local Battery\"\n",
    "    elif 40 <= row[\"BATTERY_SOC\"] < 80:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    elif 15 <= row[\"BATTERY_SOC\"] <= 40:\n",
    "        if row[\"GARAGE_EXTERNAL_POWER\"] > row[\"DEMAND_LIMIT\"]:\n",
    "            return \"Partially Covered by Local Battery\"\n",
    "        else:\n",
    "            return \"Battery Charged from Grid\"\n",
    "    # elif row[\"BATTERY_SOC\"] < 15:\n",
    "    elif row[\"BATTERY_SOC\"] < 15:\n",
    "        return \"Battery Discharge Stopped due to Battery Health\"\n",
    "    else:\n",
    "        print(row[\"BATTERY_SOC\"])\n",
    "        print(row[\"GARAGE_EXTERNAL_POWER\"])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the labeling function to create the new column \"DRAWN_FROM\"\n",
    "gt_ds[\"DRAWN_FROM\"] = gt_ds.apply(label_charging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRAWN_FROM\n",
       "Battery Charged from Grid                          54783\n",
       "Partially Covered by Local Battery                  4457\n",
       "Battery Discharge Stopped due to Battery Health      202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_ds['DRAWN_FROM'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small labeled dataset (only the part that follows GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.5 # Tolerance for the power limit\n",
    "SOC_less_15 = gt_ds[(gt_ds[\"BATTERY_SOC\"]<=15) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]<=0)]\n",
    "SOC_less_40_1 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>15) &(gt_ds[\"BATTERY_SOC\"]<40) & (gt_ds[\"GARAGE_EXTERNAL_POWER\"]<50) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]<0)]\n",
    "SOC_less_40_2 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>15) &(gt_ds[\"BATTERY_SOC\"]<40) & (gt_ds[\"GARAGE_EXTERNAL_POWER\"]<=(50+delta)) & ((50-delta)<=gt_ds[\"GARAGE_EXTERNAL_POWER\"]) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]>=0)]\n",
    "SOC_more_40 = gt_ds[(gt_ds[\"BATTERY_SOC\"]>=40) & (gt_ds[\"BATTERY_DISCHARGE_POWER\"]>=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset, that is kept: 16.313381110998957%\n"
     ]
    }
   ],
   "source": [
    "gt_ds_small = pd.concat([SOC_less_15, SOC_less_40_1, SOC_less_40_2, SOC_more_40], ignore_index=True)\n",
    "gt_ds_small = gt_ds_small.drop_duplicates()\n",
    "print(f\"Percentage of dataset, that is kept: {len(gt_ds_small)/len(gt_ds)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = gt_ds.drop(['DEMAND_LIMIT','GARAGE_EXTERNAL_POWER', 'DRAWN_FROM'], axis=1)\n",
    "target = gt_ds['DRAWN_FROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "en_targ = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class: \"Battery Charged from Grid\" is encoded as 0\n",
      "Original Class: \"Battery Discharge Stopped due to Battery Health\" is encoded as 1\n",
      "Original Class: \"Partially Covered by Local Battery\" is encoded as 2\n"
     ]
    }
   ],
   "source": [
    "# Print classes and their labels\n",
    "for label, original_class in enumerate(encoder.classes_):\n",
    "    print(f'Original Class: \"{original_class}\" is encoded as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Tensor Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LTN classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test, encode the labels into ltn Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, en_targ, test_size=0.2, random_state=42)\n",
    "features_train = torch.tensor(features_train.to_numpy()).float()\n",
    "features_test = torch.tensor(features_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_A = ltn.Constant(torch.tensor([1, 0, 0]))\n",
    "l_B = ltn.Constant(torch.tensor([0, 1, 0]))\n",
    "l_C = ltn.Constant(torch.tensor([0, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models implementation and main predicate\n",
    "\n",
    "We need two separated models because we need both logits and probabilities. Logits are used to compute the classification accuracy, while probabilities are interpreted as truth values to compute the satisfaction level of the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(4, 100, 52, 52, 3)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.unique_labels = np.unique(labels) \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices_per_class = {label: np.where(self.labels == label)[0] for label in self.unique_labels}\n",
    "\n",
    "        samples_per_class = self.batch_size // len(self.unique_labels)\n",
    "\n",
    "        for _ in range(len(self)):\n",
    "            batch_indices = []\n",
    "\n",
    "            for label in self.unique_labels:\n",
    "                class_indices = np.random.choice(indices_per_class[label], size=samples_per_class, replace=True)\n",
    "                batch_indices.extend(class_indices)\n",
    "\n",
    "\n",
    "            if len(batch_indices) < self.batch_size:\n",
    "                extra_indices = np.random.choice(np.arange(len(self.labels)), size=self.batch_size - len(batch_indices))\n",
    "                batch_indices.extend(extra_indices)\n",
    "\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(batch_indices)\n",
    "\n",
    "            yield self.data[batch_indices], self.labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use LTN to define a predicate that will make use of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities used by LTN, logistic operations, satisfaction and accuracy retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level(loader):\n",
    "    mean_sat = 0\n",
    "    for data, labels in loader:\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0])\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1])\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2])\n",
    "        mean_sat += SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A)),\n",
    "            Forall(x_B, P(x_B, l_B)),\n",
    "            Forall(x_C, P(x_C, l_C))\n",
    "        )\n",
    "    mean_sat /= len(loader)\n",
    "    return mean_sat\n",
    "\n",
    "def compute_accuracy(loader):\n",
    "    mean_accuracy = 0.0\n",
    "    for data, labels in loader:\n",
    "        predictions = mlp(data).detach().numpy()\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        mean_accuracy += accuracy_score(labels, predictions)\n",
    "\n",
    "    return mean_accuracy / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(features_train, target_train, 64, shuffle=True)\n",
    "test_loader = DataLoader(features_test, target_test, 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.2683 | Train Sat 0.770 | Test Sat 0.771 | Train Acc 0.928 | Test Acc 0.929\n",
      " epoch 20 | loss 0.2072 | Train Sat 0.792 | Test Sat 0.782 | Train Acc 0.943 | Test Acc 0.941\n",
      " epoch 40 | loss 0.2096 | Train Sat 0.793 | Test Sat 0.801 | Train Acc 0.944 | Test Acc 0.943\n",
      " epoch 60 | loss 0.2055 | Train Sat 0.799 | Test Sat 0.798 | Train Acc 0.943 | Test Acc 0.944\n",
      " epoch 80 | loss 0.2040 | Train Sat 0.795 | Test Sat 0.785 | Train Acc 0.944 | Test Acc 0.941\n",
      " epoch 100 | loss 0.2022 | Train Sat 0.802 | Test Sat 0.809 | Train Acc 0.949 | Test Acc 0.949\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) \n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) \n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) \n",
    "\n",
    "        # calculating the satisfaction level of the knowledge base, used in guided learning\n",
    "        sat_agg = SatAgg(\n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True))\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    # Here is an example of simple quering of the logistic formulas\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 119 | loss 0.2018 | Train Sat 0.801 | Test Sat 0.808 | Train Acc 0.948 | Test Acc 0.950\n"
     ]
    }
   ],
   "source": [
    "print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "\n",
    "# epoch 119 | loss 0.2018 | Train Sat 0.801 | Test Sat 0.808 | Train Acc 0.948 | Test Acc 0.950"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that model already after 20 epochs we can see Test Acc == 0.941 and the rule satisfaction on Test == 0.782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules satisfaction presentation\n",
    "Rules satisfaction allows for a simple verification of some believes, theories as to the data (or simply verification of what we thing could be a ,,rule'' as to the system behaviour). This, to some extend, is usually possible with data analysis (in case of simple rules), but as shown later on - plays a crucial role in finding a treshold and allows for a things outside of the scope of the simple data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = DataLoader(torch.tensor(features.to_numpy()).float(), torch.tensor(en_targ), 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_phi(loader, phi):\n",
    "    sat_values = []\n",
    "    for features, labels in loader:\n",
    "        for feature, label in zip(features, labels):\n",
    "            sat_values.append(phi(feature, label).value)\n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check the satisfaction level of the rule from the GT \n",
    "- If SOC < 15 than Battery Discharge Stopped due to Battery Health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discharge_stopped(tensor):\n",
    "    return tensor <= 0\n",
    "\n",
    "def Battery_SOC_small(tensor):\n",
    "    return tensor < 15 \n",
    "\n",
    "Battery_SOC_small = ltn.Predicate(None, Battery_SOC_small)\n",
    "discharge_stopped = ltn.Predicate(None, discharge_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phi(features, label):\n",
    "    sc = features[0].view(-1,1)\n",
    "    bp = features[1].view(-1,1)\n",
    "\n",
    "    bp = ltn.Variable(\"bp\", bp)\n",
    "    s = ltn.Variable(\"s\", sc)\n",
    "    return Forall(s, Implies(Battery_SOC_small(s), discharge_stopped(bp)), p=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9096)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_phi(testing_set, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partially_covered_by_local_battery(tensor_soc, tensor_garage_external_power, tensor_demand_limit):\n",
    "    condition1 = ((tensor_soc >= 40) & (tensor_soc < 80)) | ((tensor_soc >= 15) & (tensor_soc <= 40))\n",
    "    condition2 = tensor_garage_external_power > tensor_demand_limit\n",
    "    return condition1 & condition2\n",
    "\n",
    "def battery_charged_from_grid(tensor_soc, tensor_garage_external_power, tensor_demand_limit):\n",
    "    condition1 = ((tensor_soc >= 40) & (tensor_soc < 80)) | ((tensor_soc >= 15) & (tensor_soc <= 40))\n",
    "    condition2 = tensor_garage_external_power <= tensor_demand_limit\n",
    "    return condition1 & condition2\n",
    "\n",
    "partially_covered_by_local_battery_pred = ltn.Predicate(None, partially_covered_by_local_battery)\n",
    "battery_charged_from_grid_pred = ltn.Predicate(None, battery_charged_from_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_exclusivity_formula_batch(soc_batch, garage_external_power_batch, demand_limit_batch):\n",
    "    soc_var = ltn.Variable(\"soc\", soc_batch)\n",
    "    garage_external_power_var = ltn.Variable(\"garage_external_power\", garage_external_power_batch)\n",
    "    demand_limit_var = ltn.Variable(\"demand_limit\", demand_limit_batch)\n",
    "\n",
    "    return Forall(\n",
    "        [soc_var, garage_external_power_var, demand_limit_var],\n",
    "        Not(\n",
    "            And(\n",
    "                partially_covered_by_local_battery_pred(soc_var, garage_external_power_var, demand_limit_var),\n",
    "                battery_charged_from_grid_pred(soc_var, garage_external_power_var, demand_limit_var)\n",
    "            )\n",
    "        )\n",
    "    ).value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_level_in_chunks(batch_size=100):\n",
    "    soc = torch.tensor(ds_l[\"BATTERY_SOC\"].to_numpy())\n",
    "    garage_external_power = torch.tensor(ds_l[\"GARAGE_EXTERNAL_POWER\"].to_numpy())\n",
    "    demand_limit = torch.tensor(ds_l[\"DEMAND_LIMIT\"].to_numpy())\n",
    "    num_samples = len(soc)\n",
    "    sat_values = []\n",
    "    \n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        \n",
    "        soc_batch = soc[start_idx:end_idx]\n",
    "        garage_external_power_batch = garage_external_power[start_idx:end_idx]\n",
    "        demand_limit_batch = demand_limit[start_idx:end_idx]\n",
    "        \n",
    "        sat_value = mutual_exclusivity_formula_batch(soc_batch, garage_external_power_batch, demand_limit_batch)\n",
    "        sat_values.append(sat_value)\n",
    "    \n",
    "    mean_sat = torch.mean(torch.stack(sat_values))\n",
    "    return mean_sat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_exclusivity_formula(ds_l, batch_size=100):\n",
    "    # Convert dataset columns to tensors\n",
    "    soc = torch.tensor(ds_l[\"BATTERY_SOC\"].to_numpy())\n",
    "    garage_external_power = torch.tensor(ds_l[\"GARAGE_EXTERNAL_POWER\"].to_numpy())\n",
    "    demand_limit = torch.tensor(ds_l[\"DEMAND_LIMIT\"].to_numpy())\n",
    "    \n",
    "    # Compute satisfaction level in chunks\n",
    "    return compute_sat_level_in_chunks(soc, garage_external_power, demand_limit, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9998)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sat_level_in_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns a single value (threshold) given a set of features. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ThresholdModel, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :return: threshold for example x\n",
    "        \"\"\"\n",
    "        x = self.elu(self.linear1(x))\n",
    "        out = self.linear2(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = ltn.Function(ThresholdModel(input_size=1, hidden_size=8))\n",
    "mlp = MLP()\n",
    "P = ltn.Predicate(LogitsToPredicate(mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Battery_SOC_smaller(tensor, tr):\n",
    "    return tensor <= tr\n",
    "\n",
    "Battery_SOC_smaller = ltn.Predicate(None, Battery_SOC_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7 \n",
    "alpha = 0.01\n",
    "Battery_SOC_smaller2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tr - tensor + epsilon), dim=1))))\n",
    "alpha = 0.01\n",
    "Battery_SOC_larger2 = ltn.Predicate(func=lambda tensor, tr: torch.exp(-alpha * torch.sqrt(torch.sum(torch.square(tensor - tr + epsilon), dim=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.2524 | Train Sat 0.770 | Test Sat 0.774 | Train Acc 0.928 | Test Acc 0.929\n",
      "Lower treshold 1: tensor(14.7386, grad_fn=<MeanBackward0>) tensor(0.8231)\n",
      "Lower treshold 2: tensor(37.4891, grad_fn=<MeanBackward0>) tensor(0.1571)\n",
      " epoch 20 | loss 0.1650 | Train Sat 0.797 | Test Sat 0.800 | Train Acc 0.943 | Test Acc 0.942\n",
      "Lower treshold 1: tensor(23.4130, grad_fn=<MeanBackward0>) tensor(0.8875)\n",
      "Lower treshold 2: tensor(37.4974, grad_fn=<MeanBackward0>) tensor(0.0021)\n",
      " epoch 40 | loss 0.1608 | Train Sat 0.800 | Test Sat 0.805 | Train Acc 0.945 | Test Acc 0.946\n",
      "Lower treshold 1: tensor(22.1497, grad_fn=<MeanBackward0>) tensor(0.8366)\n",
      "Lower treshold 2: tensor(38.0251, grad_fn=<MeanBackward0>) tensor(0.)\n",
      " epoch 60 | loss 0.1617 | Train Sat 0.806 | Test Sat 0.808 | Train Acc 0.947 | Test Acc 0.948\n",
      "Lower treshold 1: tensor(25.5256, grad_fn=<MeanBackward0>) tensor(0.9999)\n",
      "Lower treshold 2: tensor(37.0858, grad_fn=<MeanBackward0>) tensor(0.0230)\n",
      " epoch 80 | loss 0.1598 | Train Sat 0.800 | Test Sat 0.793 | Train Acc 0.948 | Test Acc 0.947\n",
      "Lower treshold 1: tensor(24.4578, grad_fn=<MeanBackward0>) tensor(0.9767)\n",
      "Lower treshold 2: tensor(37.1939, grad_fn=<MeanBackward0>) tensor(0.0444)\n",
      " epoch 100 | loss 0.1627 | Train Sat 0.794 | Test Sat 0.795 | Train Acc 0.943 | Test Acc 0.945\n",
      "Lower treshold 1: tensor(26.3955, grad_fn=<MeanBackward0>) tensor(0.9670)\n",
      "Lower treshold 2: tensor(37.0705, grad_fn=<MeanBackward0>) tensor(0.0674)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(list(P.parameters()) + list(tmodel.parameters()), lr=0.001)\n",
    "\n",
    "for epoch in range(120):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we ground the variables with current batch data\n",
    "        x_A = ltn.Variable(\"x_A\", data[labels == 0]) # class A examples\n",
    "        x_B = ltn.Variable(\"x_B\", data[labels == 1]) # class B examples\n",
    "        x_C = ltn.Variable(\"x_C\", data[labels == 2]) # class C examples\n",
    "\n",
    "        x_B_SOC = ltn.Variable(\"x_B_SOC\", data[labels == 1][:, 0])\n",
    "        x_C_SOC = ltn.Variable(\"x_C_SOC\", data[labels == 2][:, 0])\n",
    "        x_A_SOC = ltn.Variable(\"x_A_SOC\", data[labels == 0][:, 0])\n",
    "\n",
    "        tresh1 = tmodel(x_B_SOC)\n",
    "        tresh2 = tmodel(x_A_SOC)\n",
    "        \n",
    "        tresh = ltn.Variable(\"tre1\", tresh1.value)\n",
    "        tresh2 = ltn.Variable(\"tre2\", tresh2.value)\n",
    "        \n",
    "        sat_agg = SatAgg(    \n",
    "            # there is a treshold such that SOC is smaller than treshold \n",
    "            Forall(x_A, P(x_A, l_A, training=True)),\n",
    "            Forall(x_B, P(x_B, l_B, training=True)),\n",
    "            Forall(x_C, P(x_C, l_C, training=True)),\n",
    "            Exists(tresh, Forall(x_B_SOC, Battery_SOC_smaller2(x_B_SOC, tresh), p=5), p=5),\n",
    "            Exists(tresh, Forall(x_C_SOC, Battery_SOC_larger2(x_C_SOC, tresh), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_A_SOC, Battery_SOC_smaller2(x_A_SOC, tresh2), p=5) ,p=5),\n",
    "            Exists(tresh2, Forall(x_C_SOC, Battery_SOC_larger2(x_C_SOC, tresh2), p=5) ,p=5),\n",
    "        )\n",
    "        loss = 1. - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
    "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
    "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))\n",
    "        print(\"Lower treshold 1:\", tresh.value.mean(), Forall(x_B_SOC, Battery_SOC_smaller(x_B_SOC, tresh)).value.mean())\n",
    "        print(\"Lower treshold 2:\", tresh2.value.mean(), Forall(x_A_SOC, Battery_SOC_smaller(x_A_SOC, tresh2)).value.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
